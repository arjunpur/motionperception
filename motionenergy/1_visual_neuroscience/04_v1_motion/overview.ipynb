{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direction Selectivity and Motion Processing in V1\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook, we'll explore how primary visual cortex (V1) neurons detect and represent motion. Building on our previous understanding of receptive fields and the distinction between simple and complex cells, we'll now examine how V1 neurons develop direction selectivity – a crucial step in the visual motion processing pathway.\n",
    "\n",
    "Topics we'll cover:\n",
    "- Direction selectivity in V1 neurons\n",
    "- The difference between orientation tuning and direction tuning\n",
    "- Spatiotemporal receptive fields and their inseparability\n",
    "- How space-time inseparable filters detect motion\n",
    "- The aperture problem and its implications for motion perception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import signal\n",
    "import matplotlib.cm as cm\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Set some plotting parameters\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direction Selectivity in V1\n",
    "\n",
    "While many V1 neurons respond to oriented stimuli like bars or edges regardless of their direction of motion (orientation selectivity), some V1 neurons respond preferentially when a stimulus moves in a particular direction (direction selectivity).\n",
    "\n",
    "A direction-selective neuron might respond strongly to a vertical bar moving rightward but weakly or not at all to the same bar moving leftward. This represents a fundamental computation in the visual system: extracting motion information from the changing pattern of light on the retina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orientation vs. Direction Tuning\n",
    "\n",
    "To understand direction selectivity, we first need to clarify the relationship between orientation tuning and direction tuning:\n",
    "\n",
    "- **Orientation tuning**: A neuron responds to a specific edge orientation regardless of motion direction. For example, a vertical orientation-tuned neuron responds equally to a vertical bar moving right or left.\n",
    "\n",
    "- **Direction tuning**: A neuron responds preferentially to motion in a specific direction. For example, a rightward direction-tuned neuron responds strongly to rightward motion but weakly to leftward motion.\n",
    "\n",
    "Let's visualize the difference between these two types of tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def plot_tuning_curves():\n",
    "    # Create orientation angles (0-180 degrees)\n",
    "    orientations = np.linspace(0, 180, 37)[:-1]\n",
    "    \n",
    "    # Create direction angles (0-360 degrees)\n",
    "    directions = np.linspace(0, 360, 73)[:-1]\n",
    "    \n",
    "    # Create an orientation-tuned response (peaks at 90 degrees - vertical orientation)\n",
    "    orientation_response = np.exp(-0.5 * ((orientations - 90) / 15) ** 2)\n",
    "    \n",
    "    # Create a direction-tuned response (peaks at 0 degrees - rightward motion)\n",
    "    direction_response = np.exp(-0.5 * ((directions - 0) / 30) ** 2) + \\\n",
    "                         0.1 * np.exp(-0.5 * ((directions - 180) / 30) ** 2)  # Small response to opposite direction\n",
    "    \n",
    "    # Create figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6), subplot_kw={'projection': 'polar'})\n",
    "    \n",
    "    # Plot orientation tuning (map 0-180 to 0-360 for polar plot)\n",
    "    orientation_plot = np.concatenate([orientation_response, orientation_response])\n",
    "    orientation_angles = np.deg2rad(np.concatenate([orientations, orientations+180]))\n",
    "    ax1.plot(orientation_angles, orientation_plot, 'b-')\n",
    "    ax1.fill(orientation_angles, orientation_plot, alpha=0.2)\n",
    "    ax1.set_title('Orientation Tuning (non-directional)', fontsize=14)\n",
    "    ax1.set_rticks([0.5, 1.0])\n",
    "    ax1.set_rlabel_position(45)\n",
    "    ax1.set_xticks(np.deg2rad([0, 45, 90, 135, 180, 225, 270, 315]))\n",
    "    ax1.set_xticklabels(['0°', '45°', '90°', '135°', '180°', '225°', '270°', '315°'])\n",
    "    \n",
    "    # Plot direction tuning\n",
    "    direction_angles = np.deg2rad(directions)\n",
    "    ax2.plot(direction_angles, direction_response, 'r-')\n",
    "    ax2.fill(direction_angles, direction_response, alpha=0.2)\n",
    "    ax2.set_title('Direction Tuning (rightward preferred)', fontsize=14)\n",
    "    ax2.set_rticks([0.5, 1.0])\n",
    "    ax2.set_rlabel_position(45)\n",
    "    ax2.set_xticks(np.deg2rad([0, 45, 90, 135, 180, 225, 270, 315]))\n",
    "    ax2.set_xticklabels(['0°', '45°', '90°', '135°', '180°', '225°', '270°', '315°'])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Also show a diagram to help interpret\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Schematic for orientation tuning\n",
    "    ax1.set_xlim(-5, 5)\n",
    "    ax1.set_ylim(-5, 5)\n",
    "    ax1.set_aspect('equal')\n",
    "    ax1.set_title('Orientation-Selective Neuron\\n(responds to vertical, any direction)', fontsize=14)\n",
    "    ax1.add_patch(plt.Rectangle((-4, -0.2), 8, 0.4, color='black'))\n",
    "    ax1.arrow(-3, 0, 1, 0, head_width=0.4, head_length=0.3, fc='blue', ec='blue')\n",
    "    ax1.arrow(3, 0, -1, 0, head_width=0.4, head_length=0.3, fc='blue', ec='blue')\n",
    "    ax1.text(-3, 1, 'Equal Response', color='blue', fontsize=12)\n",
    "    ax1.text(1, 1, 'Equal Response', color='blue', fontsize=12)\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([])\n",
    "    \n",
    "    # Schematic for direction tuning\n",
    "    ax2.set_xlim(-5, 5)\n",
    "    ax2.set_ylim(-5, 5)\n",
    "    ax2.set_aspect('equal')\n",
    "    ax2.set_title('Direction-Selective Neuron\\n(responds to rightward motion)', fontsize=14)\n",
    "    ax2.add_patch(plt.Rectangle((-4, -0.2), 8, 0.4, color='black'))\n",
    "    ax2.arrow(-3, 0, 1, 0, head_width=0.4, head_length=0.3, fc='red', ec='red')\n",
    "    ax2.arrow(3, 0, -1, 0, head_width=0.4, head_length=0.3, fc='gray', ec='gray', alpha=0.5)\n",
    "    ax2.text(-3, 1, 'Strong Response', color='red', fontsize=12)\n",
    "    ax2.text(1, 1, 'Weak/No Response', color='gray', fontsize=12)\n",
    "    ax2.set_xticks([])\n",
    "    ax2.set_yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_tuning_curves()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximately 30% of V1 neurons show direction selectivity, particularly in layer 4B, which projects to the middle temporal area (MT/V5) - a region specialized for motion processing that we'll explore in a later section.\n",
    "\n",
    "## Spatiotemporal Receptive Fields\n",
    "\n",
    "To understand how V1 neurons achieve direction selectivity, we need to consider their receptive fields in both space and time. These spatiotemporal receptive fields describe how a neuron responds to stimuli at different positions in the visual field and at different time points.\n",
    "\n",
    "### Space-Time Separability and Inseparability\n",
    "\n",
    "A key concept for understanding direction selectivity is whether a spatiotemporal receptive field is separable or inseparable:\n",
    "\n",
    "- **Separable receptive field**: Can be expressed as the product of separate spatial and temporal components. A separable receptive field has the same spatial profile at each time point, just scaled by the temporal response. These do not exhibit direction selectivity.\n",
    "\n",
    "- **Inseparable receptive field**: Cannot be decomposed into separate spatial and temporal components. The spatial profile changes shape over time in a specific way. These can exhibit direction selectivity.\n",
    "\n",
    "Let's visualize both types of receptive fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_spatiotemporal_rfs():\n",
    "    # Parameters\n",
    "    x = np.linspace(-10, 10, 100)  # Spatial dimension\n",
    "    t = np.linspace(0, 10, 50)      # Temporal dimension\n",
    "    \n",
    "    # Create meshgrid for visualization\n",
    "    X, T = np.meshgrid(x, t)\n",
    "    \n",
    "    # Spatial component (Gabor-like function)\n",
    "    sigma_x = 2.0\n",
    "    spatial = np.exp(-X**2 / (2*sigma_x**2)) * np.cos(2*np.pi*0.3*X)\n",
    "    \n",
    "    # Temporal component (biphasic function)\n",
    "    sigma_t = 1.0\n",
    "    alpha = 0.3\n",
    "    temporal = (1 - alpha*T) * np.exp(-T**2 / (2*sigma_t**2))\n",
    "    \n",
    "    # Separable receptive field (product of spatial and temporal components)\n",
    "    separable_rf = spatial * temporal[:, np.newaxis]\n",
    "    \n",
    "    # Inseparable receptive field (spatiotemporal tilt introduces direction selectivity)\n",
    "    velocity = 1.0  # Preferred velocity\n",
    "    X_moved = X - velocity * T  # Tilted space-time coordinates\n",
    "    spatial_moved = np.exp(-X_moved**2 / (2*sigma_x**2)) * np.cos(2*np.pi*0.3*X_moved)\n",
    "    inseparable_rf = spatial_moved * temporal[:, np.newaxis]\n",
    "    \n",
    "    return x, t, separable_rf, inseparable_rf\n",
    "\n",
    "def plot_spatiotemporal_rfs():\n",
    "    x, t, separable_rf, inseparable_rf = create_spatiotemporal_rfs()\n",
    "    \n",
    "    # Plot as heatmaps (space-time plots)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    img1 = ax1.imshow(separable_rf, aspect='auto', cmap='RdBu_r', \n",
    "                      extent=[x.min(), x.max(), t.max(), t.min()],\n",
    "                      vmin=-np.abs(separable_rf).max(), vmax=np.abs(separable_rf).max())\n",
    "    ax1.set_title('Space-Time Separable RF\\n(Non-Direction Selective)', fontsize=14)\n",
    "    ax1.set_xlabel('Space (x)', fontsize=12)\n",
    "    ax1.set_ylabel('Time (t)', fontsize=12)\n",
    "    ax1.grid(False)\n",
    "    \n",
    "    # Add a right-moving stimulus trajectory\n",
    "    ax1.plot([-8, 8], [10, 0], 'w--', alpha=0.7, linewidth=2, label='Rightward motion')\n",
    "    # Add a left-moving stimulus trajectory\n",
    "    ax1.plot([8, -8], [10, 0], 'w:', alpha=0.7, linewidth=2, label='Leftward motion')\n",
    "    ax1.legend(loc='upper center', framealpha=0.8)\n",
    "    \n",
    "    img2 = ax2.imshow(inseparable_rf, aspect='auto', cmap='RdBu_r', \n",
    "                      extent=[x.min(), x.max(), t.max(), t.min()],\n",
    "                      vmin=-np.abs(inseparable_rf).max(), vmax=np.abs(inseparable_rf).max())\n",
    "    ax2.set_title('Space-Time Inseparable RF\\n(Direction Selective to Rightward Motion)', fontsize=14)\n",
    "    ax2.set_xlabel('Space (x)', fontsize=12)\n",
    "    ax2.set_ylabel('Time (t)', fontsize=12)\n",
    "    ax2.grid(False)\n",
    "    \n",
    "    # Add a right-moving stimulus trajectory that aligns with the tilted RF\n",
    "    ax2.plot([-8, 8], [10, 0], 'w--', alpha=0.7, linewidth=2, label='Rightward motion (preferred)')\n",
    "    # Add a left-moving stimulus trajectory\n",
    "    ax2.plot([8, -8], [10, 0], 'w:', alpha=0.7, linewidth=2, label='Leftward motion')\n",
    "    ax2.legend(loc='upper center', framealpha=0.8)\n",
    "    \n",
    "    # Add colorbars\n",
    "    fig.colorbar(img1, ax=ax1, shrink=0.7)\n",
    "    fig.colorbar(img2, ax=ax2, shrink=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Now show some example temporal slices of the inseparable RF\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Select a few time points\n",
    "    time_indices = [0, 10, 20, 30, 40]\n",
    "    time_values = t[time_indices]\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(time_indices)))\n",
    "    \n",
    "    for i, (idx, color) in enumerate(zip(time_indices, colors)):\n",
    "        plt.plot(x, inseparable_rf[idx], color=color, \n",
    "                 label=f't = {time_values[i]:.1f}', linewidth=2)\n",
    "    \n",
    "    plt.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    plt.title('Spatial Profile of Direction-Selective RF at Different Time Points', fontsize=14)\n",
    "    plt.xlabel('Space (x)', fontsize=12)\n",
    "    plt.ylabel('Response', fontsize=12)\n",
    "    plt.legend(title='Time')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_spatiotemporal_rfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "\n",
    "In the space-time plots above:\n",
    "\n",
    "1. The separable RF has a consistent pattern of alternating excitatory (red) and inhibitory (blue) regions that don't change shape over time, just amplitude. It responds equally to both rightward and leftward motion.\n",
    "\n",
    "2. The inseparable RF has a slanted or tilted pattern in space-time. This tilt means that the spatial profile shifts over time, creating a preferred direction. The white dashed line (rightward motion) aligns with the tilted RF structure, resulting in strong activation.\n",
    "\n",
    "3. In the bottom plot, we can see how the spatial profile of the inseparable RF changes over time - essentially \"shifting\" to the right, which means it will respond strongly to rightward motion.\n",
    "\n",
    "## How Inseparable Filters Detect Motion\n",
    "\n",
    "To understand more intuitively how an inseparable receptive field creates direction selectivity, let's visualize what happens when a moving stimulus passes through such a receptive field.\n",
    "\n",
    "First, let's create a function to generate a moving edge stimulus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def generate_moving_edge(x, t, velocity, direction=1):\n",
    "    '''Generate a moving edge in spatiotemporal coordinates'''\n",
    "    # Create a spatiotemporal stimulus array\n",
    "    X, T = np.meshgrid(x, t)\n",
    "    \n",
    "    # Position of edge at each time point\n",
    "    edge_position = direction * velocity * T\n",
    "    \n",
    "    # Create binary edge stimulus (1 where X > edge_position, 0 elsewhere)\n",
    "    stimulus = (X > edge_position).astype(float)\n",
    "    \n",
    "    return stimulus\n",
    "\n",
    "def compute_response(stimulus, receptive_field):\n",
    "    '''Compute response of a receptive field to a stimulus'''\n",
    "    # Element-wise multiplication and summation\n",
    "    response = np.sum(stimulus * receptive_field)\n",
    "    return response\n",
    "\n",
    "def visualize_motion_detection():\n",
    "    # Get our spatiotemporal RFs\n",
    "    x, t, separable_rf, inseparable_rf = create_spatiotemporal_rfs()\n",
    "    \n",
    "    # Generate moving edge stimuli in both directions\n",
    "    velocity = 1.5\n",
    "    rightward_edge = generate_moving_edge(x, t, velocity, direction=1)\n",
    "    leftward_edge = generate_moving_edge(x, t, velocity, direction=-1)\n",
    "    \n",
    "    # Plot the stimuli and RFs\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(15, 8))\n",
    "    \n",
    "    # Plot rightward stimulus\n",
    "    axs[0, 0].imshow(rightward_edge, cmap='gray', aspect='auto',\n",
    "                     extent=[x.min(), x.max(), t.max(), t.min()])\n",
    "    axs[0, 0].set_title('Rightward Moving Edge')\n",
    "    axs[0, 0].set_xlabel('Space (x)')\n",
    "    axs[0, 0].set_ylabel('Time (t)')\n",
    "    \n",
    "    # Plot leftward stimulus\n",
    "    axs[1, 0].imshow(leftward_edge, cmap='gray', aspect='auto',\n",
    "                     extent=[x.min(), x.max(), t.max(), t.min()])\n",
    "    axs[1, 0].set_title('Leftward Moving Edge')\n",
    "    axs[1, 0].set_xlabel('Space (x)')\n",
    "    axs[1, 0].set_ylabel('Time (t)')\n",
    "    \n",
    "    # Plot separable RF\n",
    "    im1 = axs[0, 1].imshow(separable_rf, cmap='RdBu_r', aspect='auto',\n",
    "                           extent=[x.min(), x.max(), t.max(), t.min()],\n",
    "                           vmin=-np.abs(separable_rf).max(), vmax=np.abs(separable_rf).max())\n",
    "    axs[0, 1].set_title('Separable RF')\n",
    "    axs[0, 1].set_xlabel('Space (x)')\n",
    "    axs[0, 1].set_ylabel('Time (t)')\n",
    "    fig.colorbar(im1, ax=axs[0, 1], shrink=0.7)\n",
    "    \n",
    "    # Plot inseparable RF\n",
    "    im2 = axs[1, 1].imshow(inseparable_rf, cmap='RdBu_r', aspect='auto',\n",
    "                           extent=[x.min(), x.max(), t.max(), t.min()],\n",
    "                           vmin=-np.abs(inseparable_rf).max(), vmax=np.abs(inseparable_rf).max())\n",
    "    axs[1, 1].set_title('Inseparable RF (Rightward Tuned)')\n",
    "    axs[1, 1].set_xlabel('Space (x)')\n",
    "    axs[1, 1].set_ylabel('Time (t)')\n",
    "    fig.colorbar(im2, ax=axs[1, 1], shrink=0.7)\n",
    "    \n",
    "    # Compute responses and show multiplication of stimulus and RF\n",
    "    response_sep_right = rightward_edge * separable_rf\n",
    "    response_sep_left = leftward_edge * separable_rf\n",
    "    response_insep_right = rightward_edge * inseparable_rf\n",
    "    response_insep_left = leftward_edge * inseparable_rf\n",
    "    \n",
    "    # Calculate total responses\n",
    "    total_sep_right = np.sum(response_sep_right)\n",
    "    total_sep_left = np.sum(response_sep_left)\n",
    "    total_insep_right = np.sum(response_insep_right)\n",
    "    total_insep_left = np.sum(response_insep_left)\n",
    "    \n",
    "    # Normalize the inseparable responses to make the difference clearer\n",
    "    max_insep = max(abs(total_insep_right), abs(total_insep_left))\n",
    "    if max_insep > 0:  # Avoid division by zero\n",
    "        total_insep_right_norm = total_insep_right / max_insep\n",
    "        total_insep_left_norm = total_insep_left / max_insep\n",
    "    else:\n",
    "        total_insep_right_norm = total_insep_right\n",
    "        total_insep_left_norm = total_insep_left\n",
    "    \n",
    "    # Normalize the separable responses\n",
    "    max_sep = max(abs(total_sep_right), abs(total_sep_left))\n",
    "    if max_sep > 0:  # Avoid division by zero\n",
    "        total_sep_right_norm = total_sep_right / max_sep\n",
    "        total_sep_left_norm = total_sep_left / max_sep\n",
    "    else:\n",
    "        total_sep_right_norm = total_sep_right\n",
    "        total_sep_left_norm = total_sep_left\n",
    "    \n",
    "    # Plot response products visually\n",
    "    im_prod = axs[0, 2].imshow(response_sep_right, cmap='RdBu_r', aspect='auto',\n",
    "                               extent=[x.min(), x.max(), t.max(), t.min()],\n",
    "                               vmin=-np.abs(response_sep_right).max(), vmax=np.abs(response_sep_right).max())\n",
    "    axs[0, 2].set_title(f'Separable RF × Rightward Stimulus\\nResponse: {total_sep_right_norm:.2f}')\n",
    "    axs[0, 2].set_xlabel('Space (x)')\n",
    "    axs[0, 2].set_ylabel('Time (t)')\n",
    "    \n",
    "    im_prod2 = axs[1, 2].imshow(response_insep_right, cmap='RdBu_r', aspect='auto',\n",
    "                                extent=[x.min(), x.max(), t.max(), t.min()],\n",
    "                                vmin=-np.abs(response_insep_right).max(), vmax=np.abs(response_insep_right).max())\n",
    "    axs[1, 2].set_title(f'Inseparable RF × Rightward Stimulus\\nResponse: {total_insep_right_norm:.2f}')\n",
    "    axs[1, 2].set_xlabel('Space (x)')\n",
    "    axs[1, 2].set_ylabel('Time (t)')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show bar graph of responses to compare\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Separable RF responses\n",
    "    bars1 = ax1.bar(['Rightward', 'Leftward'], [total_sep_right_norm, total_sep_left_norm], color=['skyblue', 'lightgreen'])\n",
    "    ax1.set_title('Separable RF Responses', fontsize=14)\n",
    "    ax1.set_ylabel('Normalized Response', fontsize=12)\n",
    "    ax1.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        offset = 0.02 if height >= 0 else -0.08\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + offset,\n",
    "                f'{height:.2f}', ha='center', va='bottom', fontsize=12)\n",
    "    ax1.set_ylim(-1.1, 1.1)\n",
    "    \n",
    "    # Inseparable RF responses\n",
    "    bars2 = ax2.bar(['Rightward', 'Leftward'], [total_insep_right_norm, total_insep_left_norm], color=['skyblue', 'lightgreen'])\n",
    "    ax2.set_title('Inseparable RF Responses (Direction-Selective)', fontsize=14)\n",
    "    ax2.set_ylabel('Normalized Response', fontsize=12)\n",
    "    ax2.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        offset = 0.02 if height >= 0 else -0.08\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + offset,\n",
    "                f'{height:.2f}', ha='center', va='bottom', fontsize=12)\n",
    "    ax2.set_ylim(-1.1, 1.1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_motion_detection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Motion Detection\n",
    "\n",
    "The visualizations above illustrate how direction selectivity emerges from spatiotemporal inseparability:\n",
    "\n",
    "1. The separable receptive field responds approximately equally to both rightward and leftward motion because its spatial pattern remains consistent over time.\n",
    "\n",
    "2. The inseparable receptive field shows a strong positive response to rightward motion but a weaker (or negative) response to leftward motion.\n",
    "\n",
    "This direction selectivity arises because the inseparable RF has a spatiotemporal structure that aligns with the trajectory of a stimulus moving in the preferred direction. Mathematically, this tilted structure in space-time represents the velocity to which the neuron is most sensitive.\n",
    "\n",
    "## Mathematical Basis for Direction Selectivity\n",
    "\n",
    "Direction selectivity arises when a spatiotemporal receptive field is inseparable in a specific way. A completely general spatiotemporal receptive field $F(x,t)$ can be decomposed into separable components using singular value decomposition:\n",
    "\n",
    "$$F(x,t) = \\sum_{i} \\lambda_i S_i(x) T_i(t)$$\n",
    "\n",
    "Where $S_i(x)$ are spatial functions, $T_i(t)$ are temporal functions, and $\\lambda_i$ are weights.\n",
    "\n",
    "For a direction-selective neuron, at least two significant components are needed, and they must have a specific phase relationship. In the simplest case, we need a quadrature pair of spatiotemporal filters (similar to what we saw with complex cells):\n",
    "\n",
    "$$F(x,t) = S_1(x)T_1(t) + S_2(x)T_2(t)$$\n",
    "\n",
    "Where $S_1$ and $S_2$ differ in spatial phase by approximately 90 degrees, and $T_1$ and $T_2$ differ in temporal phase by approximately 90 degrees.\n",
    "\n",
    "This creates the tilted structure in space-time that responds selectively to motion in one direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Aperture Problem\n",
    "\n",
    "An important limitation in early motion processing, particularly in V1, is the \"aperture problem.\" This refers to the fact that when viewing a moving edge through a small aperture (like the small receptive fields of V1 neurons), the true motion direction of the edge can be ambiguous.\n",
    "\n",
    "Let's visualize this problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_aperture_problem_visualization():\n",
    "    # Create the figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Draw a bar (oriented at 45 degrees)\n",
    "    bar_length = 8\n",
    "    bar_width = 0.8\n",
    "    bar_angle = 45  # degrees\n",
    "    \n",
    "    # Convert to radians for calculations\n",
    "    angle_rad = np.deg2rad(bar_angle)\n",
    "    \n",
    "    # Bar center position\n",
    "    center_x, center_y = 0, 0\n",
    "    \n",
    "    # Calculate bar endpoints\n",
    "    dx = (bar_length/2) * np.cos(angle_rad)\n",
    "    dy = (bar_length/2) * np.sin(angle_rad)\n",
    "    \n",
    "    # Create bar vertices\n",
    "    perp_angle = angle_rad + np.pi/2\n",
    "    perp_dx = (bar_width/2) * np.cos(perp_angle)\n",
    "    perp_dy = (bar_width/2) * np.sin(perp_angle)\n",
    "    \n",
    "    vertices = [\n",
    "        (center_x - dx + perp_dx, center_y - dy + perp_dy),\n",
    "        (center_x + dx + perp_dx, center_y + dy + perp_dy),\n",
    "        (center_x + dx - perp_dx, center_y + dy - perp_dy),\n",
    "        (center_x - dx - perp_dx, center_y - dy - perp_dy)\n",
    "    ]\n",
    "    \n",
    "    bar = plt.Polygon(vertices, color='black')\n",
    "    ax.add_patch(bar)\n",
    "    \n",
    "    # Add true motion vector (perpendicular to the bar orientation)\n",
    "    true_motion_angle = bar_angle + 90  # perpendicular to bar orientation\n",
    "    true_motion_rad = np.deg2rad(true_motion_angle)\n",
    "    \n",
    "    motion_length = 4\n",
    "    motion_x = motion_length * np.cos(true_motion_rad)\n",
    "    motion_y = motion_length * np.sin(true_motion_rad)\n",
    "    \n",
    "    ax.arrow(center_x, center_y, motion_x, motion_y, \n",
    "             head_width=0.3, head_length=0.5, fc='blue', ec='blue', linewidth=2,\n",
    "             label='True motion (135°)')\n",
    "    \n",
    "    # Add component motion (perpendicular to bar within aperture)\n",
    "    # Create circular apertures at different positions\n",
    "    aperture_positions = [\n",
    "        (center_x - dx*0.5, center_y - dy*0.5),\n",
    "        (center_x, center_y),\n",
    "        (center_x + dx*0.5, center_y + dy*0.5)\n",
    "    ]\n",
    "    \n",
    "    aperture_radius = 1.2\n",
    "    aperture_colors = ['lightgray', 'lightgray', 'lightgray']\n",
    "    \n",
    "    for i, (ap_x, ap_y) in enumerate(aperture_positions):\n",
    "        # Draw aperture\n",
    "        aperture = plt.Circle((ap_x, ap_y), aperture_radius, \n",
    "                              fill=True, color=aperture_colors[i], alpha=0.7, \n",
    "                              ec='red', linewidth=2)\n",
    "        ax.add_patch(aperture)\n",
    "        \n",
    "        # Perpendicular motion within the aperture\n",
    "        if i == 1:  # Only draw the arrow for the central aperture\n",
    "            # Compute perpendicular vector to the bar within the aperture\n",
    "            perp_angle = angle_rad + np.pi/2\n",
    "            perp_motion_length = 2\n",
    "            perp_motion_x = perp_motion_length * np.cos(perp_angle)\n",
    "            perp_motion_y = perp_motion_length * np.sin(perp_angle)\n",
    "            \n",
    "            ax.arrow(ap_x, ap_y, perp_motion_x, perp_motion_y, \n",
    "                     head_width=0.2, head_length=0.3, fc='red', ec='red', linewidth=2,\n",
    "                     label='Perceived motion within aperture (perpendicular to bar)')\n",
    "    \n",
    "    # Add labels to show the aperture problem\n",
    "    ax.text(center_x - dx*0.5, center_y - dy*0.5 - 1.5, 'Aperture A', fontsize=12, ha='center')\n",
    "    ax.text(center_x, center_y - 1.5, 'Aperture B', fontsize=12, ha='center')\n",
    "    ax.text(center_x + dx*0.5, center_y + dy*0.5 - 1.5, 'Aperture C', fontsize=12, ha='center')\n",
    "    \n",
    "    # Add demonstration of possible motions\n",
    "    # Draw multiple possible motion vectors that could cause the same local motion\n",
    "    possible_offsets = np.linspace(-np.pi/2, np.pi/2, 5)\n",
    "    possible_vectors = []\n",
    "    \n",
    "    for offset in possible_offsets:\n",
    "        possible_angle = perp_angle + offset\n",
    "        possible_x = 2.5 * np.cos(possible_angle)\n",
    "        possible_y = 2.5 * np.sin(possible_angle)\n",
    "        \n",
    "        # Draw a dashed line indicating a possible motion vector\n",
    "        if offset != 0:  # Don't redraw the perpendicular one\n",
    "            arrow = ax.arrow(center_x + dx*0.8, center_y + dy*0.8, possible_x, possible_y, \n",
    "                             head_width=0.15, head_length=0.25, fc='green', ec='green', \n",
    "                             linewidth=1, alpha=0.5, linestyle='--')\n",
    "            possible_vectors.append(arrow)\n",
    "    \n",
    "    # Add a label for the possible motions\n",
    "    ax.text(center_x + dx*0.8 + 2, center_y + dy*0.8 + 2, 'Possible\\nmotion\\nvectors', \n",
    "            fontsize=12, color='green', ha='center')\n",
    "    \n",
    "    # Set plot limits and appearance\n",
    "    ax.set_xlim(-6, 6)\n",
    "    ax.set_ylim(-6, 6)\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlabel('x', fontsize=12)\n",
    "    ax.set_ylabel('y', fontsize=12)\n",
    "    ax.set_title('The Aperture Problem in Visual Motion Processing', fontsize=16)\n",
    "    \n",
    "    # Add a legend\n",
    "    ax.legend(loc='upper left', framealpha=0.9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "create_aperture_problem_visualization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Aperture Problem\n",
    "\n",
    "The aperture problem is a fundamental ambiguity in local motion detection:\n",
    "\n",
    "1. **Local Ambiguity**: When viewing a moving oriented edge through a small aperture (like a V1 receptive field), only the motion component perpendicular to the edge can be directly detected. This is because motion along the edge produces no change in the image within the aperture.\n",
    "\n",
    "2. **V1 Constraints**: V1 neurons with small receptive fields can only measure the component of motion perpendicular to the edge's orientation. This is shown by the red arrow in the central aperture.\n",
    "\n",
    "3. **Multiple Possible Motions**: Many different true motion directions (green arrows) could produce the same observed local motion. The true motion could be in any direction that includes the perpendicular component that we can measure.\n",
    "\n",
    "4. **Integration Required**: Solving the aperture problem requires integrating information across multiple apertures or considering additional constraints. This integration happens in higher visual areas like MT (which we'll explore in the next section).\n",
    "\n",
    "The aperture problem illustrates why early motion processing in V1 is only the first step in motion perception. Higher-level processing is needed to resolve these ambiguities and accurately perceive the global motion of objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: V1 Motion Processing\n",
    "\n",
    "In this section, we've explored how neurons in the primary visual cortex (V1) process motion information:\n",
    "\n",
    "1. **Direction Selectivity**: About 30% of V1 neurons are direction-selective, responding more strongly to motion in one direction than the opposite direction.\n",
    "\n",
    "2. **Spatiotemporal Receptive Fields**: Direction selectivity arises from inseparable spatiotemporal receptive fields that have a specific tilt or orientation in the space-time domain.\n",
    "\n",
    "3. **Inseparability Principle**: A spatiotemporal receptive field must be inseparable (cannot be expressed as a simple product of spatial and temporal components) to exhibit direction selectivity.\n",
    "\n",
    "4. **Aperture Problem**: V1 neurons with small receptive fields can only detect the component of motion perpendicular to an edge, creating ambiguity that must be resolved by higher visual areas.\n",
    "\n",
    "5. **Bridge to Motion Energy Models**: The spatiotemporal filters we've explored form the foundation for motion energy models, which we'll implement in detail in a later module.\n",
    "\n",
    "In the next section, we'll examine how the middle temporal area (MT or V5) builds on this V1 motion processing to create a more comprehensive representation of motion in the visual scene."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}