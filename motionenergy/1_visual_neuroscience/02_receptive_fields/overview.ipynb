{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Receptive Fields in the Visual Cortex\n",
    "\n",
    "## Overview\n",
    "\n",
    "Welcome to the second section of our Visual Neuroscience module! In this notebook, we'll explore receptive fields in the primary visual cortex (V1), focusing on their structure, properties, and how they process visual information. \n",
    "\n",
    "In the previous section, we examined the retina and lateral geniculate nucleus (LGN), where we encountered center-surround receptive fields. Now, we'll see how these early visual signals are transformed into more complex features in the cortex through specialized receptive fields that are selective for orientation and spatial frequency.\n",
    "\n",
    "### What we'll cover:\n",
    "- Structure and properties of V1 receptive fields\n",
    "- Gabor filters as models of V1 receptive fields\n",
    "- Spatial frequency and orientation tuning\n",
    "- Receptive field mapping techniques\n",
    "- Changes in receptive field properties across the visual hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up\n",
    "\n",
    "Let's import the libraries we'll need for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy.signal as signal\n",
    "import sys\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Add the utils package to the path\n",
    "sys.path.append('../../..')\n",
    "try:\n",
    "    from motionenergy.utils import stimuli_generation, visualization\n",
    "except ImportError:\n",
    "    print(\"Note: utils modules not found. This is expected if you haven't implemented them yet.\")\n",
    "\n",
    "# For interactive plots\n",
    "%matplotlib inline\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. From Retina/LGN to V1: The Emergence of Orientation Selectivity\n",
    "\n",
    "In the previous section, we explored center-surround receptive fields in the retina and LGN. These cells respond best to spots of light and are not selective for orientation. However, when we move to the primary visual cortex (V1), we find neurons with fundamentally different response properties.\n",
    "\n",
    "### The Classic Hubel and Wiesel Experiments\n",
    "\n",
    "In the late 1950s and early 1960s, David Hubel and Torsten Wiesel conducted groundbreaking experiments recording from individual neurons in the visual cortex of cats. They discovered that V1 neurons respond most strongly to bars or edges with specific orientations in specific locations in the visual field.\n",
    "\n",
    "This discovery led to a fundamental insight about visual processing: the visual system builds increasingly complex representations through hierarchical processing, with each stage extracting more sophisticated features from the visual input.\n",
    "\n",
    "### The Feed-Forward Model of Orientation Selectivity\n",
    "\n",
    "How do orientation-selective receptive fields emerge from center-surround inputs? Hubel and Wiesel proposed a simple feed-forward model:\n",
    "\n",
    "1. Multiple center-surround LGN cells with receptive fields arranged along a line provide input to a V1 cell\n",
    "2. When a bar of light with the correct orientation falls on these aligned LGN receptive fields, they all fire simultaneously\n",
    "3. The V1 cell integrates these inputs and fires, exhibiting orientation selectivity\n",
    "\n",
    "Let's visualize this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lgn_receptive_field(size=64, sigma_center=2, sigma_surround=4, position=(0, 0), polarity='ON'):\n",
    "    \"\"\"Create a center-surround receptive field like those in LGN.\"\"\"\n",
    "    x = np.linspace(-size/2, size/2, size)\n",
    "    y = np.linspace(-size/2, size/2, size)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    # Shift position\n",
    "    X = X - position[0]\n",
    "    Y = Y - position[1]\n",
    "    \n",
    "    # Create center and surround components\n",
    "    center = np.exp(-(X**2 + Y**2) / (2 * sigma_center**2))\n",
    "    surround = np.exp(-(X**2 + Y**2) / (2 * sigma_surround**2))\n",
    "    \n",
    "    # Normalize\n",
    "    center = center / np.max(center)\n",
    "    surround = surround / np.max(surround)\n",
    "    \n",
    "    # Combine center and surround based on polarity\n",
    "    if polarity == 'ON':\n",
    "        rf = center - 0.5 * surround\n",
    "    else:  # OFF\n",
    "        rf = -center + 0.5 * surround\n",
    "    \n",
    "    return rf\n",
    "\n",
    "def visualize_v1_from_lgn_model():\n",
    "    # Create a row of LGN cells (for simplicity, all ON-center)\n",
    "    positions = [(i*8 - 16, 0) for i in range(5)]\n",
    "    lgn_rfs = [create_lgn_receptive_field(position=pos) for pos in positions]\n",
    "    \n",
    "    # Create a simple stimulus: a bar at 45 degrees\n",
    "    size = 64\n",
    "    stimulus = np.zeros((size, size))\n",
    "    for i in range(size):\n",
    "        if 22 <= i <= 42:\n",
    "            stimulus[i, i] = 1\n",
    "    \n",
    "    # Calculate LGN responses\n",
    "    lgn_responses = [np.sum(rf * stimulus) for rf in lgn_rfs]\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    # Show the stimulus\n",
    "    axs[0, 0].imshow(stimulus, cmap='gray')\n",
    "    axs[0, 0].set_title('Stimulus (45° Bar)')\n",
    "    axs[0, 0].axis('off')\n",
    "    \n",
    "    # Show LGN receptive fields and responses\n",
    "    cmap = plt.cm.RdBu_r\n",
    "    combined_rf = np.zeros_like(lgn_rfs[0])\n",
    "    \n",
    "    for i, (rf, response) in enumerate(zip(lgn_rfs, lgn_responses)):\n",
    "        # Add to combined RF (for visualization only, with scaling)\n",
    "        combined_rf += rf * 0.5  \n",
    "        \n",
    "        # Show individual RFs\n",
    "        if i < 2:  # Just show two examples to save space\n",
    "            axs[0, i+1].imshow(rf, cmap=cmap)\n",
    "            axs[0, i+1].set_title(f'LGN Cell {i+1} RF')\n",
    "            axs[0, i+1].axis('off')\n",
    "    \n",
    "    # Show combined LGN input\n",
    "    im = axs[1, 0].imshow(combined_rf, cmap=cmap)\n",
    "    axs[1, 0].set_title('Combined LGN Input')\n",
    "    axs[1, 0].axis('off')\n",
    "    plt.colorbar(im, ax=axs[1, 0])\n",
    "    \n",
    "    # Show LGN responses\n",
    "    bars = axs[1, 1].bar(range(len(lgn_responses)), lgn_responses)\n",
    "    axs[1, 1].set_title('LGN Cell Responses')\n",
    "    axs[1, 1].set_xlabel('LGN Cell')\n",
    "    axs[1, 1].set_ylabel('Response')\n",
    "    axs[1, 1].set_xticks(range(len(lgn_responses)))\n",
    "    axs[1, 1].set_ylim(-0.1, 0.5)\n",
    "    \n",
    "    # Show V1 cell response\n",
    "    v1_response = sum(lgn_responses)\n",
    "    axs[1, 2].bar(0, v1_response, color='green')\n",
    "    axs[1, 2].set_title('V1 Cell Response')\n",
    "    axs[1, 2].set_xticks([0])\n",
    "    axs[1, 2].set_xticklabels(['V1 Cell'])\n",
    "    axs[1, 2].set_ylabel('Response')\n",
    "    axs[1, 2].set_ylim(0, 2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return lgn_responses, v1_response\n",
    "\n",
    "# Visualize the feed-forward model\n",
    "lgn_responses, v1_response = visualize_v1_from_lgn_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple feed-forward model provides an intuitive framework for understanding how orientation selectivity could emerge. However, in reality, V1 receptive fields are more complex and involve additional mechanisms like lateral inhibition and feedback connections.\n",
    "\n",
    "Modern research has shown that V1 receptive fields arise from a combination of:\n",
    "- Feed-forward connections from the LGN\n",
    "- Lateral connections between V1 neurons\n",
    "- Feedback connections from higher visual areas\n",
    "- Complex inhibitory and excitatory interactions\n",
    "\n",
    "These mechanisms contribute to the rich and diverse set of receptive field properties found in V1 neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gabor Filters as Models of V1 Receptive Fields\n",
    "\n",
    "One of the most successful models for V1 receptive fields is the Gabor filter, which provides a good approximation of the spatial structure of orientation-selective cells in the visual cortex.\n",
    "\n",
    "A Gabor filter is the product of a sinusoidal plane wave and a Gaussian envelope. Mathematically, it can be expressed as:\n",
    "\n",
    "$$g(x, y; \\lambda, \\theta, \\psi, \\sigma, \\gamma) = \\exp\\left(-\\frac{x'^2 + \\gamma^2 y'^2}{2\\sigma^2}\\right) \\cos\\left(2\\pi\\frac{x'}{\\lambda} + \\psi\\right)$$\n",
    "\n",
    "where:\n",
    "- $x' = x\\cos\\theta + y\\sin\\theta$\n",
    "- $y' = -x\\sin\\theta + y\\cos\\theta$\n",
    "- $\\lambda$ = wavelength (spatial frequency)\n",
    "- $\\theta$ = orientation\n",
    "- $\\psi$ = phase offset\n",
    "- $\\sigma$ = standard deviation of the Gaussian envelope\n",
    "- $\\gamma$ = spatial aspect ratio\n",
    "\n",
    "Let's implement a Gabor filter function and visualize how different parameters affect its appearance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabor_filter(size=64, wavelength=10, orientation=0, phase=0, sigma=10, aspect_ratio=0.5):\n",
    "    \"\"\"Create a Gabor filter.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    size : int\n",
    "        Size of the filter (pixels)\n",
    "    wavelength : float\n",
    "        Wavelength of the sinusoidal component (pixels)\n",
    "    orientation : float\n",
    "        Orientation (radians)\n",
    "    phase : float\n",
    "        Phase offset (radians)\n",
    "    sigma : float\n",
    "        Standard deviation of the Gaussian envelope\n",
    "    aspect_ratio : float\n",
    "        Spatial aspect ratio of the Gaussian (y/x)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    gabor : ndarray\n",
    "        2D array with the Gabor filter\n",
    "    \"\"\"\n",
    "    # Create coordinates\n",
    "    x = np.linspace(-size/2, size/2, size)\n",
    "    y = np.linspace(-size/2, size/2, size)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    # Rotation\n",
    "    X_rot = X * np.cos(orientation) + Y * np.sin(orientation)\n",
    "    Y_rot = -X * np.sin(orientation) + Y * np.cos(orientation)\n",
    "    \n",
    "    # Gaussian envelope\n",
    "    gaussian = np.exp(-(X_rot**2 + (aspect_ratio * Y_rot)**2) / (2 * sigma**2))\n",
    "    \n",
    "    # Sinusoidal carrier\n",
    "    sinusoid = np.cos(2 * np.pi * X_rot / wavelength + phase)\n",
    "    \n",
    "    # Gabor filter\n",
    "    gabor = gaussian * sinusoid\n",
    "    \n",
    "    return gabor\n",
    "\n",
    "# Create and visualize a basic Gabor filter\n",
    "basic_gabor = gabor_filter()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(basic_gabor, cmap='RdBu_r')\n",
    "plt.colorbar(label='Filter Value')\n",
    "plt.title('Gabor Filter (Default Parameters)')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create an interactive visualization to explore how changing parameters affects the Gabor filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(\n",
    "    wavelength=widgets.FloatSlider(min=4, max=20, step=1, value=10, description='Wavelength:'),\n",
    "    orientation=widgets.FloatSlider(min=0, max=np.pi, step=np.pi/12, value=0, description='Orientation:'),\n",
    "    phase=widgets.FloatSlider(min=0, max=2*np.pi, step=np.pi/6, value=0, description='Phase:'),\n",
    "    sigma=widgets.FloatSlider(min=4, max=20, step=1, value=10, description='Sigma:'),\n",
    "    aspect_ratio=widgets.FloatSlider(min=0.2, max=1.0, step=0.1, value=0.5, description='Aspect Ratio:')\n",
    ")\n",
    "def update_gabor(wavelength, orientation, phase, sigma, aspect_ratio):\n",
    "    \"\"\"Update the Gabor filter visualization based on parameter changes.\"\"\"\n",
    "    # Create the Gabor filter\n",
    "    gb = gabor_filter(\n",
    "        wavelength=wavelength,\n",
    "        orientation=orientation,\n",
    "        phase=phase,\n",
    "        sigma=sigma,\n",
    "        aspect_ratio=aspect_ratio\n",
    "    )\n",
    "    \n",
    "    # Plot the filter\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # 2D image\n",
    "    im = axs[0].imshow(gb, cmap='RdBu_r')\n",
    "    axs[0].set_title('Gabor Filter')\n",
    "    axs[0].axis('off')\n",
    "    plt.colorbar(im, ax=axs[0])\n",
    "    \n",
    "    # 3D surface plot\n",
    "    x = np.linspace(-32, 32, 64)\n",
    "    y = np.linspace(-32, 32, 64)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    ax = axs[1]\n",
    "    ax = plt.subplot(1, 2, 2, projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, gb, cmap='coolwarm', linewidth=0, antialiased=True)\n",
    "    ax.set_title('3D Visualization')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Filter Value')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Gabor Filters?\n",
    "\n",
    "Gabor filters provide an excellent model for V1 receptive fields for several reasons:\n",
    "\n",
    "1. **Biological accuracy**: Receptive fields of V1 simple cells closely resemble Gabor functions when mapped experimentally\n",
    "\n",
    "2. **Optimal joint resolution**: Gabor filters achieve the theoretical lower bound for joint uncertainty in the spatial and frequency domains (similar to the uncertainty principle in quantum mechanics)\n",
    "\n",
    "3. **Feature extraction**: They effectively extract oriented edges and textures, which are fundamental features in natural images\n",
    "\n",
    "4. **Mathematical tractability**: Gabor functions have well-understood mathematical properties that make them useful for modeling and analysis\n",
    "\n",
    "These properties make Gabor filters not only good models for biological vision but also useful tools in computer vision and image processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Orientation and Spatial Frequency Tuning\n",
    "\n",
    "Two key properties of V1 neurons are their selectivity for orientation and spatial frequency. Let's explore these properties in detail.\n",
    "\n",
    "### Orientation Tuning\n",
    "\n",
    "Orientation tuning describes how a neuron's response varies with the orientation of a stimulus. Most V1 neurons respond preferentially to stimuli with a specific orientation and less to stimuli with other orientations. The relationship between stimulus orientation and neural response can be plotted as an orientation tuning curve.\n",
    "\n",
    "Let's simulate the orientation tuning of a V1 neuron using our Gabor filter model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grating_stimulus(size=64, orientation=0, spatial_freq=0.1, phase=0):\n",
    "    \"\"\"Create a sine wave grating stimulus.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    size : int\n",
    "        Size of the stimulus (pixels)\n",
    "    orientation : float\n",
    "        Orientation of the grating (radians)\n",
    "    spatial_freq : float\n",
    "        Spatial frequency of the grating (cycles/pixel)\n",
    "    phase : float\n",
    "        Phase of the grating (radians)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    grating : ndarray\n",
    "        2D array with the grating stimulus\n",
    "    \"\"\"\n",
    "    # Create coordinates\n",
    "    x = np.linspace(-size/2, size/2, size)\n",
    "    y = np.linspace(-size/2, size/2, size)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    # Rotate coordinates\n",
    "    X_rot = X * np.cos(orientation) + Y * np.sin(orientation)\n",
    "    \n",
    "    # Create grating\n",
    "    grating = np.sin(2 * np.pi * X_rot * spatial_freq + phase)\n",
    "    \n",
    "    return grating\n",
    "\n",
    "def compute_response(stimulus, receptive_field):\n",
    "    \"\"\"Compute the response of a neuron with the given receptive field to a stimulus.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    stimulus : ndarray\n",
    "        2D array with the stimulus\n",
    "    receptive_field : ndarray\n",
    "        2D array with the receptive field\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    response : float\n",
    "        Response of the neuron\n",
    "    \"\"\"\n",
    "    # Normalize receptive field\n",
    "    rf_normalized = receptive_field / np.sqrt(np.sum(receptive_field**2))\n",
    "    \n",
    "    # Compute response (dot product)\n",
    "    response = np.sum(stimulus * rf_normalized)\n",
    "    \n",
    "    # Apply a simple rectification (to simulate firing rates can't be negative)\n",
    "    response = max(0, response)\n",
    "    \n",
    "    return response\n",
    "\n",
    "def plot_orientation_tuning():\n",
    "    \"\"\"Plot orientation tuning curve for a V1 neuron.\"\"\"\n",
    "    # Create a Gabor filter as our model V1 receptive field\n",
    "    preferred_orientation = np.pi / 4  # 45 degrees\n",
    "    rf = gabor_filter(orientation=preferred_orientation, wavelength=8, sigma=8)\n",
    "    \n",
    "    # Test orientations\n",
    "    orientations = np.linspace(0, np.pi, 24)  # 0 to 180 degrees\n",
    "    responses = []\n",
    "    \n",
    "    # Compute responses to gratings at different orientations\n",
    "    for theta in orientations:\n",
    "        stimulus = grating_stimulus(orientation=theta, spatial_freq=1/8)  # Match wavelength\n",
    "        response = compute_response(stimulus, rf)\n",
    "        responses.append(response)\n",
    "    \n",
    "    # Normalize responses\n",
    "    responses = np.array(responses)\n",
    "    responses = responses / np.max(responses)\n",
    "    \n",
    "    # Plot tuning curve\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Plot receptive field\n",
    "    axs[0].imshow(rf, cmap='RdBu_r')\n",
    "    axs[0].set_title('V1 Receptive Field\\n(Preferred: 45°)')\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    # Plot example stimulus\n",
    "    example_stimulus = grating_stimulus(orientation=preferred_orientation, spatial_freq=1/8)\n",
    "    axs[1].imshow(example_stimulus, cmap='gray')\n",
    "    axs[1].set_title('Example Stimulus\\n(Orientation: 45°)')\n",
    "    axs[1].axis('off')\n",
    "    \n",
    "    # Plot tuning curve\n",
    "    orientations_deg = orientations * 180 / np.pi\n",
    "    axs[2].plot(orientations_deg, responses, 'o-', linewidth=2)\n",
    "    axs[2].axvline(preferred_orientation * 180 / np.pi, color='r', linestyle='--', alpha=0.5, label='Preferred')\n",
    "    axs[2].set_xlabel('Orientation (degrees)')\n",
    "    axs[2].set_ylabel('Normalized Response')\n",
    "    axs[2].set_title('Orientation Tuning Curve')\n",
    "    axs[2].set_xlim(0, 180)\n",
    "    axs[2].set_xticks(np.arange(0, 181, 30))\n",
    "    axs[2].set_ylim(0, 1.05)\n",
    "    axs[2].grid(True, alpha=0.3)\n",
    "    axs[2].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return orientations_deg, responses\n",
    "\n",
    "# Plot orientation tuning curve\n",
    "orientations, responses = plot_orientation_tuning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orientation Tuning Width and Selectivity\n",
    "\n",
    "The width of the orientation tuning curve indicates how selective a neuron is for orientation. Neurons with narrow tuning curves respond only to a small range of orientations, while those with broader tuning curves are less selective.\n",
    "\n",
    "V1 neurons vary in their orientation selectivity, with some showing very sharp tuning (high selectivity) and others showing broader tuning (lower selectivity). This diversity of tuning properties allows the visual system to represent orientation information with different levels of precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Frequency Tuning\n",
    "\n",
    "In addition to orientation selectivity, V1 neurons are also tuned for spatial frequency, which determines the scale at which they detect features. Spatial frequency is measured in cycles per degree of visual angle and refers to how rapidly a visual pattern repeats over space.\n",
    "\n",
    "Let's simulate the spatial frequency tuning of a V1 neuron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spatial_frequency_tuning():\n",
    "    \"\"\"Plot spatial frequency tuning curve for a V1 neuron.\"\"\"\n",
    "    # Create a Gabor filter as our model V1 receptive field\n",
    "    preferred_wavelength = 8  # pixels\n",
    "    preferred_sf = 1 / preferred_wavelength  # cycles/pixel\n",
    "    rf = gabor_filter(wavelength=preferred_wavelength, sigma=8)\n",
    "    \n",
    "    # Test spatial frequencies (as wavelengths)\n",
    "    wavelengths = np.logspace(np.log10(2), np.log10(32), 20)  # 2 to 32 pixels\n",
    "    spatial_freqs = 1 / wavelengths  # cycles/pixel\n",
    "    responses = []\n",
    "    \n",
    "    # Compute responses to gratings at different spatial frequencies\n",
    "    for sf in spatial_freqs:\n",
    "        stimulus = grating_stimulus(orientation=0, spatial_freq=sf)\n",
    "        response = compute_response(stimulus, rf)\n",
    "        responses.append(response)\n",
    "    \n",
    "    # Normalize responses\n",
    "    responses = np.array(responses)\n",
    "    responses = responses / np.max(responses)\n",
    "    \n",
    "    # Plot tuning curve\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Plot receptive field\n",
    "    axs[0].imshow(rf, cmap='RdBu_r')\n",
    "    axs[0].set_title(f'V1 Receptive Field\\n(Preferred SF: {preferred_sf:.3f} cycles/pixel)')\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    # Plot example stimuli\n",
    "    # Create a subplot with three different spatial frequencies\n",
    "    sf_examples = [spatial_freqs[0], preferred_sf, spatial_freqs[-1]]\n",
    "    sf_stimuli = [grating_stimulus(orientation=0, spatial_freq=sf) for sf in sf_examples]\n",
    "    \n",
    "    # Combine into one image with dividing lines\n",
    "    example_img = np.zeros((64, 64 * 3))\n",
    "    for i, stim in enumerate(sf_stimuli):\n",
    "        example_img[:, i*64:(i+1)*64] = stim\n",
    "    \n",
    "    axs[1].imshow(example_img, cmap='gray')\n",
    "    axs[1].set_title('Example Stimuli\\n(Low, Preferred, High Spatial Frequency)')\n",
    "    axs[1].axis('off')\n",
    "    \n",
    "    # Plot tuning curve\n",
    "    axs[2].semilogx(spatial_freqs, responses, 'o-', linewidth=2)\n",
    "    axs[2].axvline(preferred_sf, color='r', linestyle='--', alpha=0.5, label='Preferred')\n",
    "    axs[2].set_xlabel('Spatial Frequency (cycles/pixel)')\n",
    "    axs[2].set_ylabel('Normalized Response')\n",
    "    axs[2].set_title('Spatial Frequency Tuning Curve')\n",
    "    axs[2].set_xlim(spatial_freqs.min(), spatial_freqs.max())\n",
    "    axs[2].set_ylim(0, 1.05)\n",
    "    axs[2].grid(True, alpha=0.3)\n",
    "    axs[2].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return spatial_freqs, responses\n",
    "\n",
    "# Plot spatial frequency tuning curve\n",
    "spatial_freqs, sf_responses = plot_spatial_frequency_tuning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bandpass Filtering Properties\n",
    "\n",
    "The spatial frequency tuning curve shows that V1 neurons act as bandpass filters, responding most strongly to a specific range of spatial frequencies and less to frequencies that are either too low or too high. This bandpass filtering property allows the visual system to analyze images at multiple spatial scales.\n",
    "\n",
    "Different V1 neurons are tuned to different spatial frequencies, allowing the visual system to simultaneously represent fine details (high spatial frequencies) and coarse structure (low spatial frequencies) in the visual scene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Receptive Field Mapping Techniques\n",
    "\n",
    "How do neuroscientists determine the structure and properties of receptive fields in the visual cortex? Several techniques have been developed to map receptive fields experimentally. Let's explore some of these methods.\n",
    "\n",
    "### Hubel and Wiesel's Method: Bars and Edges\n",
    "\n",
    "The classic approach used by Hubel and Wiesel involved presenting bars or edges at different positions and orientations while recording from a single neuron. By systematically varying the stimulus parameters and noting when the neuron fired, they could map out its receptive field structure.\n",
    "\n",
    "This labor-intensive method provided the first insights into the orientation selectivity of V1 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_classic_rf_mapping():\n",
    "    \"\"\"Simulate the classic Hubel and Wiesel receptive field mapping.\"\"\"\n",
    "    # Create a Gabor filter as our \"ground truth\" receptive field\n",
    "    true_rf = gabor_filter(size=32, wavelength=8, orientation=np.pi/4, sigma=6)  # 45 degrees\n",
    "    \n",
    "    # Define the positions and orientations to test\n",
    "    positions = np.linspace(-12, 12, 5)\n",
    "    orientations = np.linspace(0, np.pi, 6)  # 0 to 180 degrees\n",
    "    \n",
    "    # Initialize response matrix\n",
    "    responses = np.zeros((len(positions), len(orientations)))\n",
    "    \n",
    "    # Test each position and orientation\n",
    "    for i, pos in enumerate(positions):\n",
    "        for j, theta in enumerate(orientations):\n",
    "            # Create a bar stimulus\n",
    "            stimulus = np.zeros((32, 32))\n",
    "            for k in range(32):\n",
    "                for l in range(32):\n",
    "                    # Rotate coordinates\n",
    "                    x_rot = (l - 16) * np.cos(theta) + (k - 16) * np.sin(theta)\n",
    "                    if abs(x_rot - pos) < 1.5:  # Bar width = 3 pixels\n",
    "                        stimulus[k, l] = 1\n",
    "            \n",
    "            # Compute response\n",
    "            response = compute_response(stimulus, true_rf)\n",
    "            responses[i, j] = response\n",
    "    \n",
    "    # Normalize responses\n",
    "    responses = responses / np.max(responses)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Show the true receptive field\n",
    "    axs[0].imshow(true_rf, cmap='RdBu_r')\n",
    "    axs[0].set_title('True Receptive Field')\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    # Show the measured responses\n",
    "    im = axs[1].imshow(responses, cmap='viridis', extent=[\n",
    "        0, 180,  # x-axis: orientation in degrees\n",
    "        positions[-1], positions[0]  # y-axis: position\n",
    "    ])\n",
    "    axs[1].set_xlabel('Orientation (degrees)')\n",
    "    axs[1].set_ylabel('Position')\n",
    "    axs[1].set_title('Measured Responses')\n",
    "    plt.colorbar(im, ax=axs[1], label='Normalized Response')\n",
    "    \n",
    "    # Show an example stimulus\n",
    "    best_i, best_j = np.unravel_index(np.argmax(responses), responses.shape)\n",
    "    best_pos = positions[best_i]\n",
    "    best_ori = orientations[best_j]\n",
    "    \n",
    "    # Create the best stimulus\n",
    "    best_stimulus = np.zeros((32, 32))\n",
    "    for k in range(32):\n",
    "        for l in range(32):\n",
    "            x_rot = (l - 16) * np.cos(best_ori) + (k - 16) * np.sin(best_ori)\n",
    "            if abs(x_rot - best_pos) < 1.5:\n",
    "                best_stimulus[k, l] = 1\n",
    "    \n",
    "    axs[2].imshow(best_stimulus, cmap='gray')\n",
    "    axs[2].set_title(f'Optimal Stimulus\\n(Orientation: {best_ori * 180 / np.pi:.1f}°, Position: {best_pos:.1f})')\n",
    "    axs[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return responses\n",
    "\n",
    "# Simulate classic receptive field mapping\n",
    "classic_responses = simulate_classic_rf_mapping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverse Correlation: White Noise Analysis\n",
    "\n",
    "A more modern approach is reverse correlation, also known as white noise analysis or spike-triggered averaging. This method involves:\n",
    "\n",
    "1. Presenting a random stimulus (white noise) to the visual system\n",
    "2. Recording the neuron's spikes in response to this stimulus\n",
    "3. Averaging the stimuli that preceded each spike\n",
    "\n",
    "This average gives an estimate of the receptive field structure without requiring prior assumptions about its properties.\n",
    "\n",
    "Let's simulate this technique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_reverse_correlation():\n",
    "    \"\"\"Simulate reverse correlation (white noise) receptive field mapping.\"\"\"\n",
    "    # Create a Gabor filter as our \"ground truth\" receptive field\n",
    "    true_rf = gabor_filter(size=32, wavelength=6, orientation=np.pi/4, sigma=5)\n",
    "    \n",
    "    # Create sequence of white noise stimuli\n",
    "    n_frames = 10000\n",
    "    noise_stimuli = np.random.normal(0, 1, (n_frames, 32, 32))\n",
    "    \n",
    "    # Compute responses\n",
    "    responses = np.array([compute_response(stim, true_rf) for stim in noise_stimuli])\n",
    "    \n",
    "    # Select stimuli that elicited strong responses (simulating spikes)\n",
    "    threshold = np.percentile(responses, 95)  # Top 5% of responses\n",
    "    spike_indices = np.where(responses > threshold)[0]\n",
    "    spike_triggered_stimuli = noise_stimuli[spike_indices]\n",
    "    \n",
    "    # Compute spike-triggered average (STA)\n",
    "    sta = np.mean(spike_triggered_stimuli, axis=0)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Show the true receptive field\n",
    "    axs[0].imshow(true_rf, cmap='RdBu_r')\n",
    "    axs[0].set_title('True Receptive Field')\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    # Show example noise stimulus\n",
    "    axs[1].imshow(noise_stimuli[0], cmap='gray')\n",
    "    axs[1].set_title('Example Noise Stimulus')\n",
    "    axs[1].axis('off')\n",
    "    \n",
    "    # Show the estimated receptive field (STA)\n",
    "    axs[2].imshow(sta, cmap='RdBu_r')\n",
    "    axs[2].set_title('Estimated RF (Spike-Triggered Average)')\n",
    "    axs[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate the correlation between true and estimated RF\n",
    "    correlation = np.corrcoef(true_rf.flatten(), sta.flatten())[0, 1]\n",
    "    print(f\"Correlation between true and estimated RF: {correlation:.3f}\")\n",
    "    \n",
    "    return sta\n",
    "\n",
    "# Simulate reverse correlation mapping\n",
    "estimated_rf = simulate_reverse_correlation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Techniques\n",
    "\n",
    "Modern neuroscience employs several more sophisticated techniques for mapping receptive fields:\n",
    "\n",
    "1. **Subspace Reverse Correlation**: Uses structured stimuli (like Gabor patches) instead of white noise\n",
    "\n",
    "2. **Receptive Field Estimation using GLMs**: Uses generalized linear models to estimate receptive fields from responses to complex stimuli\n",
    "\n",
    "3. **Calcium Imaging**: Allows simultaneous recording from many neurons, providing maps of receptive fields across a neural population\n",
    "\n",
    "4. **fMRI Retinotopic Mapping**: Maps receptive fields at a coarser scale in humans using non-invasive imaging\n",
    "\n",
    "These techniques have revealed the rich diversity of receptive field properties in the visual cortex and how these properties change across the visual hierarchy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Receptive Field Changes Across the Visual Hierarchy\n",
    "\n",
    "As visual information flows from the retina through the visual cortex and into higher visual areas, receptive fields undergo systematic changes in size and complexity. Let's explore these changes and their functional significance.\n",
    "\n",
    "### Receptive Field Size Progression\n",
    "\n",
    "One of the most consistent changes across the visual hierarchy is an increase in receptive field size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_rf_size_progression():\n",
    "    \"\"\"Visualize how receptive field size increases across the visual hierarchy.\"\"\"\n",
    "    # Create receptive fields of different sizes (simulating different visual areas)\n",
    "    size = 128\n",
    "    \n",
    "    # Create retina/LGN center-surround RF\n",
    "    retina_rf = create_lgn_receptive_field(size=size, sigma_center=3, sigma_surround=6, polarity='ON')\n",
    "    \n",
    "    # Create V1 simple cell RF (small Gabor)\n",
    "    v1_rf = gabor_filter(size=size, wavelength=8, orientation=np.pi/4, sigma=6, aspect_ratio=0.6)\n",
    "    \n",
    "    # Create V2 RF (larger Gabor, potentially more complex)\n",
    "    v2_rf = gabor_filter(size=size, wavelength=12, orientation=np.pi/4, sigma=12, aspect_ratio=0.7)\n",
    "    \n",
    "    # Create V4 RF (even larger)\n",
    "    v4_rf = gabor_filter(size=size, wavelength=18, orientation=np.pi/4, sigma=20, aspect_ratio=0.8)\n",
    "    \n",
    "    # Create IT RF (large and less structured, simulated as a large Gaussian)\n",
    "    x = np.linspace(-size/2, size/2, size)\n",
    "    y = np.linspace(-size/2, size/2, size)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    it_rf = np.exp(-(X**2 + Y**2) / (2 * 30**2))\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(15, 5))\n",
    "    regions = ['Retina/LGN', 'V1', 'V2', 'V4', 'IT']\n",
    "    rfs = [retina_rf, v1_rf, v2_rf, v4_rf, it_rf]\n",
    "    cmaps = ['gray', 'RdBu_r', 'RdBu_r', 'RdBu_r', 'gray']\n",
    "    \n",
    "    for i, (region, rf, cmap) in enumerate(zip(regions, rfs, cmaps)):\n",
    "        axs[i].imshow(rf, cmap=cmap)\n",
    "        axs[i].set_title(f'{region}\\nRF Size: {np.sqrt(np.sum(rf**2)):.1f}')\n",
    "        axs[i].axis('off')\n",
    "        \n",
    "        # Add a circle to visualize RF size\n",
    "        if i > 0:  # Skip for Retina/LGN since it's not a simple size measure\n",
    "            sigma = [6, 12, 20, 30][i-1]\n",
    "            circle = plt.Circle((size/2, size/2), 2*sigma, fill=False, edgecolor='red')\n",
    "            axs[i].add_patch(circle)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# Visualize RF size progression\n",
    "visualize_rf_size_progression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional Significance of Changing Receptive Field Properties\n",
    "\n",
    "These changes in receptive field properties across the visual hierarchy serve important functional roles:\n",
    "\n",
    "1. **Integration of Information**: Larger receptive fields in higher areas integrate information from larger regions of visual space\n",
    "\n",
    "2. **Feature Complexity**: More complex properties in higher areas allow detection of more complex visual features\n",
    "\n",
    "3. **Invariance**: Larger and more complex receptive fields contribute to invariant recognition (recognizing objects regardless of exact position, size, etc.)\n",
    "\n",
    "4. **Spatial and Feature Hierarchies**: The visual system simultaneously builds both a spatial hierarchy (from small to large) and a feature hierarchy (from simple to complex)\n",
    "\n",
    "These hierarchical changes allow the visual system to transform the pixel-like representation in the retina into increasingly abstract and useful representations of the visual world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Applying Gabor Filters to Natural Images\n",
    "\n",
    "To better understand how V1 receptive fields process visual information, let's apply Gabor filters to natural images. This will demonstrate how these filters extract oriented features from complex scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_natural_image(size=128):\n",
    "    \"\"\"Create a simple natural-like image with edges and textures.\"\"\"\n",
    "    # Start with a blank image\n",
    "    image = np.zeros((size, size))\n",
    "    \n",
    "    # Add some geometric shapes\n",
    "    # Rectangle\n",
    "    image[20:60, 30:70] = 0.8\n",
    "    \n",
    "    # Triangle\n",
    "    for i in range(30):\n",
    "        width = int(i * 30 / 30)\n",
    "        image[80+i, 80-width:80+width] = 0.6\n",
    "    \n",
    "    # Add some texture\n",
    "    texture = np.random.normal(0, 0.1, (size, size))\n",
    "    image += texture\n",
    "    \n",
    "    # Add a gradient background\n",
    "    x = np.linspace(0, 1, size)\n",
    "    X, Y = np.meshgrid(x, x)\n",
    "    gradient = 0.2 * (X + Y) / 2\n",
    "    image += gradient\n",
    "    \n",
    "    # Ensure values are in [0, 1]\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def apply_gabor_filter_bank(image, n_orientations=6, n_wavelengths=3):\n",
    "    \"\"\"Apply a bank of Gabor filters to an image and visualize the responses.\"\"\"\n",
    "    # Create a bank of Gabor filters with different orientations and wavelengths\n",
    "    orientations = np.linspace(0, np.pi, n_orientations, endpoint=False)\n",
    "    wavelengths = [4, 8, 16][:n_wavelengths]  # Different scales\n",
    "    \n",
    "    # Apply each filter and store the responses\n",
    "    responses = []\n",
    "    filters = []\n",
    "    \n",
    "    for wavelength in wavelengths:\n",
    "        for orientation in orientations:\n",
    "            # Create the filter\n",
    "            gabor = gabor_filter(\n",
    "                size=32,  # Smaller filter for efficiency\n",
    "                wavelength=wavelength,\n",
    "                orientation=orientation,\n",
    "                sigma=wavelength * 0.75,  # Scale sigma with wavelength\n",
    "                aspect_ratio=0.6\n",
    "            )\n",
    "            filters.append(gabor)\n",
    "            \n",
    "            # Apply the filter using convolution\n",
    "            response = signal.convolve2d(image, gabor, mode='same', boundary='symm')\n",
    "            responses.append(response)\n",
    "    \n",
    "    # Visualize\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    gs = fig.add_gridspec(n_wavelengths+1, n_orientations+1)\n",
    "    \n",
    "    # Show the original image in the top-left corner\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.set_title('Original Image')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Show the filters in the first row and column\n",
    "    for i, wavelength in enumerate(wavelengths):\n",
    "        for j, orientation in enumerate(orientations):\n",
    "            filter_idx = i * n_orientations + j\n",
    "            \n",
    "            # Show filter in the first row\n",
    "            if i == 0:\n",
    "                ax = fig.add_subplot(gs[0, j+1])\n",
    "                ax.imshow(filters[filter_idx], cmap='RdBu_r')\n",
    "                ax.set_title(f'Orientation: {orientation*180/np.pi:.0f}°')\n",
    "                ax.axis('off')\n",
    "            \n",
    "            # Show wavelength in the first column\n",
    "            if j == 0:\n",
    "                ax = fig.add_subplot(gs[i+1, 0])\n",
    "                ax.imshow(filters[filter_idx], cmap='RdBu_r')\n",
    "                ax.set_title(f'Wavelength: {wavelength}')\n",
    "                ax.axis('off')\n",
    "            \n",
    "            # Show filter response\n",
    "            ax = fig.add_subplot(gs[i+1, j+1])\n",
    "            ax.imshow(np.abs(responses[filter_idx]), cmap='viridis')\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return responses\n",
    "\n",
    "# Create a natural-like image\n",
    "natural_image = create_natural_image()\n",
    "\n",
    "# Apply Gabor filter bank\n",
    "gabor_responses = apply_gabor_filter_bank(natural_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction with Gabor Filters\n",
    "\n",
    "As you can see from the visualization above, Gabor filters act as feature detectors that extract oriented structures from the image. Each filter responds most strongly to edges or textures that match its orientation and spatial frequency.\n",
    "\n",
    "Some key observations:\n",
    "\n",
    "1. **Orientation Selectivity**: Each filter responds strongly to edges aligned with its orientation and weakly to edges with perpendicular orientations\n",
    "\n",
    "2. **Scale Selectivity**: Filters with different wavelengths (scales) detect features at different resolutions\n",
    "\n",
    "3. **Edge Enhancement**: The filters highlight edges and boundaries in the image while suppressing uniform regions\n",
    "\n",
    "4. **Directional Information**: The filters extract information about the directionality of features in the image\n",
    "\n",
    "These properties make Gabor filters extremely effective at extracting meaningful features from natural scenes, which is why they serve as good models for V1 receptive fields and are also widely used in computer vision applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've explored the structure and properties of receptive fields in the visual cortex, with a focus on primary visual cortex (V1). We've covered:\n",
    "\n",
    "1. **The emergence of orientation selectivity** in V1 from center-surround inputs from the LGN\n",
    "\n",
    "2. **Gabor filters** as mathematical models of V1 receptive fields\n",
    "\n",
    "3. **Orientation and spatial frequency tuning** properties of V1 neurons\n",
    "\n",
    "4. **Receptive field mapping techniques** used in neuroscience research\n",
    "\n",
    "5. **Changes in receptive field properties** across the visual hierarchy\n",
    "\n",
    "6. **Application of Gabor filters** to natural images to extract oriented features\n",
    "\n",
    "These receptive field properties form the foundation for more complex visual processing, including motion detection, which we'll explore in the upcoming modules. In the next section, we'll focus on simple and complex cells, which represent two distinct functional classes of neurons in V1 with different receptive field properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "If you're interested in learning more about receptive fields in the visual cortex, here are some resources to explore:\n",
    "\n",
    "### Papers and Books\n",
    "- Hubel, D. H., & Wiesel, T. N. (1962). Receptive fields, binocular interaction and functional architecture in the cat's visual cortex. *The Journal of Physiology*, 160(1), 106-154.\n",
    "  - The classic paper introducing orientation selectivity in V1\n",
    "\n",
    "- De Valois, R. L., & De Valois, K. K. (1988). *Spatial Vision*. Oxford University Press.\n",
    "  - Comprehensive book on spatial vision, including detailed treatment of receptive fields\n",
    "\n",
    "- Jones, J. P., & Palmer, L. A. (1987). An evaluation of the two-dimensional Gabor filter model of simple receptive fields in cat striate cortex. *Journal of Neurophysiology*, 58(6), 1233-1258.\n",
    "  - Key paper demonstrating the Gabor model of V1 receptive fields\n",
    "\n",
    "### Online Resources\n",
    "- [Scholarpedia: Receptive Fields](http://www.scholarpedia.org/article/Receptive_field)\n",
    "  - Detailed encyclopedia article on receptive fields\n",
    "\n",
    "- [Coursera: Neural Data Science](https://www.coursera.org/learn/neural-data-science)\n",
    "  - Course covering techniques for analyzing neural data, including receptive field mapping\n",
    "\n",
    "- [Neuronal Dynamics: From Single Neurons to Networks and Models of Cognition](https://neuronaldynamics.epfl.ch/)\n",
    "  - Free online textbook with chapters on visual receptive fields"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}