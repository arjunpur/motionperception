{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bridging Biology and Models: From Neural Mechanisms to Motion Energy\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook, we'll explore the crucial connection between biological visual systems and computational models of motion perception. Building on our understanding of the visual pathway from retina to MT, we'll now establish a clear bridge to the motion energy model framework that we'll implement in the next module.\n",
    "\n",
    "Topics we'll cover:\n",
    "- Connecting biological neurons to computational model components\n",
    "- Mapping spatiotemporal filters to V1/MT neural responses\n",
    "- Understanding how motion energy relates to neural computations\n",
    "- Exploring how biological constraints inform model design\n",
    "- Establishing the foundations for the upcoming motion energy model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import signal\n",
    "import matplotlib.cm as cm\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Set some plotting parameters\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting Neural Mechanisms to Computational Models\n",
    "\n",
    "Throughout this module, we've explored how the visual system processes motion information, from retinal ganglion cells to MT neurons. Now, we'll connect these biological mechanisms to the computational framework of motion energy models.\n",
    "\n",
    "The connection between neural mechanisms and computational models serves several important purposes:\n",
    "\n",
    "1. **Validation**: Models based on neural principles can be validated against physiological data\n",
    "2. **Prediction**: Computational models can generate predictions for new neural experiments\n",
    "3. **Understanding**: Models provide a formal framework for understanding complex neural processes\n",
    "4. **Application**: Biologically-inspired models can be applied to computer vision tasks\n",
    "\n",
    "Let's start by examining how key components of the visual system map to elements in motion energy models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bio_model_mapping_visual():\n",
    "    \"\"\"Create a visual representation of the biological-to-model mapping\"\"\"\n",
    "    # Create figure and axes\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Set up the plotting area\n",
    "    ax.set_xlim(0, 10)\n",
    "    ax.set_ylim(0, 10)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Define biological components (left side)\n",
    "    bio_components = [\n",
    "        \"Retinal Ganglion Cells\\n(Center-Surround)\",\n",
    "        \"LGN Magnocellular Cells\\n(Temporal Processing)\",\n",
    "        \"V1 Simple Cells\\n(Orientation Selectivity)\",\n",
    "        \"V1 Complex Cells\\n(Phase Invariance)\",\n",
    "        \"Direction-Selective V1 Cells\\n(Space-Time Inseparability)\",\n",
    "        \"MT Pattern Cells\\n(Integration)\"\n",
    "    ]\n",
    "    \n",
    "    # Define computational model components (right side)\n",
    "    model_components = [\n",
    "        \"Spatial Filtering\\n(Edge Detection)\",\n",
    "        \"Temporal Filtering\\n(Transient Response)\",\n",
    "        \"Oriented Spatiotemporal Filters\\n(Gabor Functions)\",\n",
    "        \"Quadrature Pairs\\n(Squaring & Summing)\",\n",
    "        \"Motion Energy Computation\\n(Directional Tuning)\",\n",
    "        \"Filter Banks & Integration\\n(Velocity Estimation)\"\n",
    "    ]\n",
    "    \n",
    "    # Positions for bio components (left side)\n",
    "    bio_y_positions = np.linspace(9, 1, len(bio_components))\n",
    "    bio_x_position = 2\n",
    "    \n",
    "    # Positions for model components (right side)\n",
    "    model_y_positions = np.linspace(9, 1, len(model_components))\n",
    "    model_x_position = 8\n",
    "    \n",
    "    # Draw biological components\n",
    "    bio_boxes = []\n",
    "    for i, (component, y) in enumerate(zip(bio_components, bio_y_positions)):\n",
    "        # Draw box\n",
    "        box = plt.Rectangle((bio_x_position - 1.5, y - 0.4), 3, 0.8, \n",
    "                           fc='lightblue', ec='blue', alpha=0.7)\n",
    "        ax.add_patch(box)\n",
    "        bio_boxes.append(box)\n",
    "        \n",
    "        # Add text\n",
    "        ax.text(bio_x_position, y, component, ha='center', va='center', fontsize=10)\n",
    "    \n",
    "    # Draw model components\n",
    "    model_boxes = []\n",
    "    for i, (component, y) in enumerate(zip(model_components, model_y_positions)):\n",
    "        # Draw box\n",
    "        box = plt.Rectangle((model_x_position - 1.5, y - 0.4), 3, 0.8, \n",
    "                           fc='lightgreen', ec='darkgreen', alpha=0.7)\n",
    "        ax.add_patch(box)\n",
    "        model_boxes.append(box)\n",
    "        \n",
    "        # Add text\n",
    "        ax.text(model_x_position, y, component, ha='center', va='center', fontsize=10)\n",
    "    \n",
    "    # Draw connecting arrows\n",
    "    arrow_props = dict(arrowstyle='->', linewidth=1.5, color='gray')\n",
    "    for i in range(len(bio_components)):\n",
    "        ax.annotate(\"\", xy=(model_x_position - 1.5, model_y_positions[i]), \n",
    "                   xytext=(bio_x_position + 1.5, bio_y_positions[i]),\n",
    "                   arrowprops=arrow_props)\n",
    "    \n",
    "    # Add titles\n",
    "    ax.text(bio_x_position, 9.8, \"Biological Visual System\", ha='center', va='center', \n",
    "           fontsize=14, fontweight='bold', color='blue')\n",
    "    ax.text(model_x_position, 9.8, \"Motion Energy Model\", ha='center', va='center', \n",
    "           fontsize=14, fontweight='bold', color='darkgreen')\n",
    "    \n",
    "    # Add hierarchical arrows on each side\n",
    "    hier_arrow_props = dict(arrowstyle='->', linewidth=2, color='black')\n",
    "    ax.annotate(\"\", xy=(bio_x_position, 1.5), xytext=(bio_x_position, 9.5),\n",
    "               arrowprops=dict(arrowstyle='<->', linewidth=2, color='black'))\n",
    "    ax.annotate(\"\", xy=(model_x_position, 1.5), xytext=(model_x_position, 9.5),\n",
    "               arrowprops=dict(arrowstyle='<->', linewidth=2, color='black'))\n",
    "    \n",
    "    # Add annotations for hierarchical processing\n",
    "    ax.text(bio_x_position - 0.8, 5.5, \"Hierarchical\\nProcessing\", rotation=90, \n",
    "           va='center', fontsize=12)\n",
    "    ax.text(model_x_position - 0.8, 5.5, \"Computational\\nStages\", rotation=90, \n",
    "           va='center', fontsize=12)\n",
    "    \n",
    "    plt.title(\"Mapping Between Biological Visual System and Motion Energy Model\", fontsize=16, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "create_bio_model_mapping_visual()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Mapping of Visual System Components to Model Elements\n",
    "\n",
    "Let's explore each of these mappings in more detail:\n",
    "\n",
    "### 1. Retinal Ganglion Cells → Spatial Filtering\n",
    "\n",
    "The center-surround receptive fields of retinal ganglion cells perform initial spatial filtering of visual input. This corresponds to the first stage of spatial filtering in motion energy models, which often implement:\n",
    "\n",
    "- Edge detection through center-surround mechanisms\n",
    "- Contrast enhancement through lateral inhibition\n",
    "- Basic feature extraction from raw visual input\n",
    "\n",
    "In computational models, these operations are typically implemented using spatial filters like Gaussian derivatives or Difference-of-Gaussians (DoG) filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_dog_filters():\n",
    "    \"\"\"Compare biological center-surround fields with DoG computational filters\"\"\"\n",
    "    # Create spatial coordinates\n",
    "    x = np.linspace(-10, 10, 200)\n",
    "    y = np.linspace(-10, 10, 200)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    # Create DoG filter (computational model)\n",
    "    def dog_filter(X, Y, sigma_center=1.0, sigma_surround=2.0):\n",
    "        # Compute radial distance\n",
    "        R = np.sqrt(X**2 + Y**2)\n",
    "        \n",
    "        # Compute DoG\n",
    "        center = np.exp(-0.5 * (R/sigma_center)**2) / (2 * np.pi * sigma_center**2)\n",
    "        surround = np.exp(-0.5 * (R/sigma_surround)**2) / (2 * np.pi * sigma_surround**2)\n",
    "        \n",
    "        # Normalize to ensure zero sum\n",
    "        dog = center - 0.5 * surround\n",
    "        return dog\n",
    "    \n",
    "    # Create filters for ON and OFF RGCs\n",
    "    on_center_filter = dog_filter(X, Y, sigma_center=1.0, sigma_surround=2.0)\n",
    "    off_center_filter = -on_center_filter\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(15, 8))\n",
    "    \n",
    "    # Left column: Biological RGC RF schematic\n",
    "    # ON center cell\n",
    "    axs[0, 0].add_patch(plt.Circle((0, 0), 1.5, fc='green', alpha=0.5, ec='green'))\n",
    "    axs[0, 0].add_patch(plt.Circle((0, 0), 0.7, fc='red', alpha=0.7, ec='red'))\n",
    "    axs[0, 0].set_xlim(-2.5, 2.5)\n",
    "    axs[0, 0].set_ylim(-2.5, 2.5)\n",
    "    axs[0, 0].set_aspect('equal')\n",
    "    axs[0, 0].set_title('ON-Center RGC\\nBiological Receptive Field', fontsize=12)\n",
    "    axs[0, 0].set_xticks([])\n",
    "    axs[0, 0].set_yticks([])\n",
    "    axs[0, 0].text(0, -2, \"+ Center, - Surround\", ha='center')\n",
    "    \n",
    "    # OFF center cell\n",
    "    axs[1, 0].add_patch(plt.Circle((0, 0), 1.5, fc='red', alpha=0.5, ec='red'))\n",
    "    axs[1, 0].add_patch(plt.Circle((0, 0), 0.7, fc='green', alpha=0.7, ec='green'))\n",
    "    axs[1, 0].set_xlim(-2.5, 2.5)\n",
    "    axs[1, 0].set_ylim(-2.5, 2.5)\n",
    "    axs[1, 0].set_aspect('equal')\n",
    "    axs[1, 0].set_title('OFF-Center RGC\\nBiological Receptive Field', fontsize=12)\n",
    "    axs[1, 0].set_xticks([])\n",
    "    axs[1, 0].set_yticks([])\n",
    "    axs[1, 0].text(0, -2, \"- Center, + Surround\", ha='center')\n",
    "    \n",
    "    # Middle column: Computational DoG filters\n",
    "    on_dog = axs[0, 1].imshow(on_center_filter, cmap='RdBu_r', extent=[-10, 10, -10, 10])\n",
    "    axs[0, 1].set_title('ON-Center Computational Filter\\n(Difference of Gaussians)', fontsize=12)\n",
    "    plt.colorbar(on_dog, ax=axs[0, 1], shrink=0.7)\n",
    "    \n",
    "    off_dog = axs[1, 1].imshow(off_center_filter, cmap='RdBu_r', extent=[-10, 10, -10, 10])\n",
    "    axs[1, 1].set_title('OFF-Center Computational Filter\\n(Difference of Gaussians)', fontsize=12)\n",
    "    plt.colorbar(off_dog, ax=axs[1, 1], shrink=0.7)\n",
    "    \n",
    "    # Right column: 1D profiles\n",
    "    axs[0, 2].plot(x, on_center_filter[len(y)//2, :], 'b-', linewidth=2)\n",
    "    axs[0, 2].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    axs[0, 2].set_title('ON-Center Filter Profile', fontsize=12)\n",
    "    axs[0, 2].set_xlabel('Space (x)')\n",
    "    axs[0, 2].set_ylabel('Filter value')\n",
    "    \n",
    "    axs[1, 2].plot(x, off_center_filter[len(y)//2, :], 'r-', linewidth=2)\n",
    "    axs[1, 2].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    axs[1, 2].set_title('OFF-Center Filter Profile', fontsize=12)\n",
    "    axs[1, 2].set_xlabel('Space (x)')\n",
    "    axs[1, 2].set_ylabel('Filter value')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "compare_dog_filters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LGN Magnocellular Cells → Temporal Filtering\n",
    "\n",
    "LGN magnocellular cells, with their sensitivity to temporal changes, perform temporal filtering of visual input. In motion energy models, this corresponds to temporal filters that capture dynamic aspects of visual stimuli:\n",
    "\n",
    "- Transient (high temporal frequency) vs. sustained (low temporal frequency) responses\n",
    "- Sensitivity to rapid changes in illumination\n",
    "- Temporal differentiation of visual signals\n",
    "\n",
    "Computationally, these are often implemented using biphasic temporal filters that differentiate the input over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_temporal_responses():\n",
    "    \"\"\"Compare magnocellular temporal responses with computational temporal filters\"\"\"\n",
    "    # Create time points\n",
    "    t = np.linspace(0, 300, 300)  # in milliseconds\n",
    "    \n",
    "    # Biological magno response function (simplified)\n",
    "    def magno_response(t, tau=15, tau_inh=20, delay_inh=10, strength_inh=0.8):\n",
    "        # Excitatory component\n",
    "        excite = (t/tau) * np.exp(1 - t/tau) * (t > 0)\n",
    "        \n",
    "        # Delayed inhibitory component\n",
    "        inhib = (t/tau_inh) * np.exp(1 - t/tau_inh) * (t > delay_inh)\n",
    "        \n",
    "        # Combine to get biphasic response\n",
    "        response = excite - strength_inh * inhib\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    # Computational temporal filter (typically used in motion energy models)\n",
    "    def computational_temp_filter(t, omega=2*np.pi/100, tau=20):\n",
    "        # Derivative of Gaussian envelope multiplied by sinusoid\n",
    "        envelope = np.exp(-(t/tau)**2/2)\n",
    "        derivative = -t/(tau**2) * envelope\n",
    "        sinusoid = np.sin(omega*t)\n",
    "        \n",
    "        return derivative * sinusoid\n",
    "    \n",
    "    # Create the responses\n",
    "    biological_response = magno_response(t)\n",
    "    computational_filter = computational_temp_filter(t)\n",
    "    \n",
    "    # Normalize for comparison\n",
    "    biological_response = biological_response / np.max(np.abs(biological_response))\n",
    "    computational_filter = computational_filter / np.max(np.abs(computational_filter))\n",
    "    \n",
    "    # Create a stimulus with abrupt onset\n",
    "    stimulus = np.zeros_like(t)\n",
    "    stimulus[50:] = 1  # step input at t=50ms\n",
    "    \n",
    "    # Convolve with both filters to get responses\n",
    "    bio_output = np.convolve(stimulus, biological_response, mode='same')\n",
    "    comp_output = np.convolve(stimulus, computational_filter, mode='same')\n",
    "    \n",
    "    # Normalize outputs\n",
    "    bio_output = bio_output / np.max(np.abs(bio_output))\n",
    "    comp_output = comp_output / np.max(np.abs(comp_output))\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(14, 8))\n",
    "    \n",
    "    # Plot biological filter\n",
    "    axs[0, 0].plot(t, biological_response, 'b-', linewidth=2)\n",
    "    axs[0, 0].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    axs[0, 0].set_title('Biological Magnocellular Temporal Response', fontsize=12)\n",
    "    axs[0, 0].set_xlabel('Time (ms)')\n",
    "    axs[0, 0].set_ylabel('Response')\n",
    "    axs[0, 0].set_xlim(0, 200)\n",
    "    \n",
    "    # Plot computational filter\n",
    "    axs[0, 1].plot(t, computational_filter, 'g-', linewidth=2)\n",
    "    axs[0, 1].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    axs[0, 1].set_title('Computational Temporal Filter', fontsize=12)\n",
    "    axs[0, 1].set_xlabel('Time (ms)')\n",
    "    axs[0, 1].set_ylabel('Filter value')\n",
    "    axs[0, 1].set_xlim(0, 200)\n",
    "    \n",
    "    # Plot the stimulus\n",
    "    axs[1, 0].plot(t, stimulus, 'k-', linewidth=1.5)\n",
    "    axs[1, 0].set_title('Step Stimulus', fontsize=12)\n",
    "    axs[1, 0].set_xlabel('Time (ms)')\n",
    "    axs[1, 0].set_ylabel('Intensity')\n",
    "    \n",
    "    # Plot responses to stimulus\n",
    "    axs[1, 1].plot(t, bio_output, 'b-', linewidth=2, label='Biological response')\n",
    "    axs[1, 1].plot(t, comp_output, 'g-', linewidth=2, label='Computational response')\n",
    "    axs[1, 1].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    axs[1, 1].set_title('Responses to Step Stimulus', fontsize=12)\n",
    "    axs[1, 1].set_xlabel('Time (ms)')\n",
    "    axs[1, 1].set_ylabel('Response')\n",
    "    axs[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "compare_temporal_responses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. V1 Simple Cells → Oriented Spatiotemporal Filters\n",
    "\n",
    "V1 simple cells with orientation selectivity map to oriented spatiotemporal filters in motion energy models. These are typically implemented as Gabor functions, which capture:\n",
    "\n",
    "- Orientation selectivity\n",
    "- Spatial frequency tuning\n",
    "- Localized edge detection\n",
    "\n",
    "In the motion energy model, these oriented filters form the basis of the spatiotemporal receptive fields that will subsequently be made directionally selective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_simple_cells():\n",
    "    \"\"\"Compare V1 simple cells with corresponding computational Gabor filters\"\"\"\n",
    "    # Create spatial coordinates\n",
    "    x = np.linspace(-10, 10, 200)\n",
    "    y = np.linspace(-10, 10, 200)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    # Function to create a Gabor filter\n",
    "    def gabor_filter(X, Y, theta=0, sigma_x=2, sigma_y=1, freq=0.1, phase=0):\n",
    "        # Rotate coordinates\n",
    "        X_theta = X * np.cos(theta) + Y * np.sin(theta)\n",
    "        Y_theta = -X * np.sin(theta) + Y * np.cos(theta)\n",
    "        \n",
    "        # Create Gaussian envelope\n",
    "        gaussian = np.exp(-0.5 * (X_theta**2 / sigma_x**2 + Y_theta**2 / sigma_y**2))\n",
    "        \n",
    "        # Create sinusoidal component\n",
    "        sinusoid = np.cos(2 * np.pi * freq * X_theta + phase)\n",
    "        \n",
    "        # Combine to get Gabor\n",
    "        gabor = gaussian * sinusoid\n",
    "        \n",
    "        return gabor\n",
    "    \n",
    "    # Create Gabor filters at different orientations\n",
    "    orientations = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    gabors = [gabor_filter(X, Y, theta=theta) for theta in orientations]\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    \n",
    "    # Plot biological simple cell schematics (top row)\n",
    "    for i, theta in enumerate(orientations):\n",
    "        # Create a schematic representation of a simple cell\n",
    "        # We'll use the Gabor but include indicators of excitatory/inhibitory regions\n",
    "        gabor = gabor_filter(X, Y, theta=theta)\n",
    "        \n",
    "        # Display the Gabor as a biological RF\n",
    "        im = axs[0, i].imshow(gabor, cmap='RdBu_r', extent=[-10, 10, -10, 10])\n",
    "        \n",
    "        # Add annotations for excitatory/inhibitory regions\n",
    "        excitatory_mask = gabor > 0.2\n",
    "        inhibitory_mask = gabor < -0.2\n",
    "        \n",
    "        # Find centers of excitatory/inhibitory regions\n",
    "        if np.any(excitatory_mask):\n",
    "            y_exc, x_exc = np.where(excitatory_mask)\n",
    "            exc_center_y = np.mean(y_exc) / len(y) * 20 - 10\n",
    "            exc_center_x = np.mean(x_exc) / len(x) * 20 - 10\n",
    "            axs[0, i].text(exc_center_x, exc_center_y, \"+\", color='black', fontsize=12, \n",
    "                          ha='center', va='center', fontweight='bold')\n",
    "        \n",
    "        if np.any(inhibitory_mask):\n",
    "            y_inh, x_inh = np.where(inhibitory_mask)\n",
    "            inh_center_y = np.mean(y_inh) / len(y) * 20 - 10\n",
    "            inh_center_x = np.mean(x_inh) / len(x) * 20 - 10\n",
    "            axs[0, i].text(inh_center_x, inh_center_y, \"−\", color='black', fontsize=12, \n",
    "                          ha='center', va='center', fontweight='bold')\n",
    "        \n",
    "        axs[0, i].set_title(f'V1 Simple Cell\\nOrientation: {int(theta*180/np.pi)}°', fontsize=12)\n",
    "        axs[0, i].set_xticks([])\n",
    "        axs[0, i].set_yticks([])\n",
    "    \n",
    "    # Add a title for the top row\n",
    "    fig.text(0.5, 0.95, 'Biological Simple Cells', ha='center', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Plot computational Gabor filters (bottom row)\n",
    "    for i, (theta, gabor) in enumerate(zip(orientations, gabors)):\n",
    "        im = axs[1, i].imshow(gabor, cmap='RdBu_r', extent=[-10, 10, -10, 10])\n",
    "        axs[1, i].set_title(f'Computational Gabor Filter\\nOrientation: {int(theta*180/np.pi)}°', fontsize=12)\n",
    "        axs[1, i].set_xticks([])\n",
    "        axs[1, i].set_yticks([])\n",
    "    \n",
    "    # Add a title for the bottom row\n",
    "    fig.text(0.5, 0.48, 'Computational Gabor Filters', ha='center', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add a colorbar\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "    cbar.set_label('Filter value', rotation=270, labelpad=20)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "compare_simple_cells()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. V1 Complex Cells → Quadrature Pairs and Energy Computation\n",
    "\n",
    "V1 complex cells, with their phase invariance, map to the quadrature pair mechanism in motion energy models. This correspondence includes:\n",
    "\n",
    "- Pairs of filters with 90° phase difference (quadrature pairs)\n",
    "- Squaring and summing operations to achieve phase invariance\n",
    "- Nonlinear integration of simple cell outputs\n",
    "\n",
    "This computational approach mirrors the biological phase invariance of complex cells, allowing the model to respond consistently regardless of the exact phase of the stimulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def illustrate_quadrature_pairs():\n",
    "    \"\"\"Illustrate the relationship between complex cells and quadrature pairs\"\"\"\n",
    "    # Create spatial dimension\n",
    "    x = np.linspace(-10, 10, 200)\n",
    "    \n",
    "    # Create simple gabor functions with quadrature phase relationship\n",
    "    def gabor_1d(x, freq=0.3, sigma=2.0, phase=0):\n",
    "        gaussian = np.exp(-0.5 * (x / sigma) ** 2)\n",
    "        sinusoid = np.cos(2 * np.pi * freq * x + phase)\n",
    "        return gaussian * sinusoid\n",
    "    \n",
    "    # Create even and odd Gabors (90° phase difference)\n",
    "    even_gabor = gabor_1d(x, phase=0)          # cosine phase\n",
    "    odd_gabor = gabor_1d(x, phase=np.pi/2)     # sine phase\n",
    "    \n",
    "    # Create a stimulus grating with varying phase\n",
    "    def stimulus_grating(x, freq=0.3, phase=0):\n",
    "        return np.cos(2 * np.pi * freq * x + phase)\n",
    "    \n",
    "    # Compute response for a range of stimulus phases\n",
    "    phases = np.linspace(0, 2*np.pi, 8, endpoint=False)\n",
    "    simple_responses = []\n",
    "    complex_responses = []\n",
    "    \n",
    "    for phase in phases:\n",
    "        # Create stimulus with this phase\n",
    "        stimulus = stimulus_grating(x, phase=phase)\n",
    "        \n",
    "        # Compute responses of even and odd filters\n",
    "        even_response = np.sum(stimulus * even_gabor)\n",
    "        odd_response = np.sum(stimulus * odd_gabor)\n",
    "        \n",
    "        # Simple cell response (just the even gabor response)\n",
    "        simple_responses.append(even_response)\n",
    "        \n",
    "        # Complex cell response (energy: sum of squares)\n",
    "        energy = even_response**2 + odd_response**2\n",
    "        complex_responses.append(energy)\n",
    "    \n",
    "    # Normalize responses for easier comparison\n",
    "    simple_responses = np.array(simple_responses) / np.max(np.abs(simple_responses))\n",
    "    complex_responses = np.array(complex_responses) / np.max(complex_responses)\n",
    "    \n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    gs = fig.add_gridspec(3, 3)\n",
    "    \n",
    "    # Top left: Biological Simple Cell\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.imshow(np.outer(np.ones(30), even_gabor), cmap='RdBu_r', aspect='auto',\n",
    "              extent=[x.min(), x.max(), -3, 3])\n",
    "    ax1.set_title('Biological V1 Simple Cell\\n(Phase Sensitive)', fontsize=12)\n",
    "    ax1.set_xlabel('Space (x)')\n",
    "    ax1.set_yticks([])\n",
    "    \n",
    "    # Top center: Biological Complex Cell\n",
    "    ax2 = fig.add_subplot(gs[0, 1:3])\n",
    "    ax2.text(0.5, 0.5, 'Complex Cell Combines\\nMultiple Simple Cells\\nwith Different Phases', \n",
    "            ha='center', va='center', fontsize=14)\n",
    "    ax2.set_title('Biological V1 Complex Cell\\n(Phase Invariant)', fontsize=12)\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # Middle row: Computational Quadrature Pair\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    ax3.plot(x, even_gabor, 'b-', linewidth=2)\n",
    "    ax3.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax3.set_title('Even Gabor Filter\\n(Cosine Phase)', fontsize=12)\n",
    "    ax3.set_xlabel('Space (x)')\n",
    "    ax3.set_ylabel('Filter value')\n",
    "    \n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    ax4.plot(x, odd_gabor, 'r-', linewidth=2)\n",
    "    ax4.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax4.set_title('Odd Gabor Filter\\n(Sine Phase)', fontsize=12)\n",
    "    ax4.set_xlabel('Space (x)')\n",
    "    ax4.set_ylabel('Filter value')\n",
    "    \n",
    "    ax5 = fig.add_subplot(gs[1, 2])\n",
    "    ax5.text(0.5, 0.5, 'Energy = Even² + Odd²\\n(Square and Sum)', \n",
    "            ha='center', va='center', fontsize=14)\n",
    "    ax5.set_title('Motion Energy Computation', fontsize=12)\n",
    "    ax5.axis('off')\n",
    "    \n",
    "    # Bottom row: Response vs Phase\n",
    "    ax6 = fig.add_subplot(gs[2, :])\n",
    "    ax6.plot(phases * 180/np.pi, simple_responses, 'b-o', linewidth=2, label='Simple Cell / Even Gabor')\n",
    "    ax6.plot(phases * 180/np.pi, complex_responses, 'r-o', linewidth=2, label='Complex Cell / Energy Model')\n",
    "    ax6.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax6.set_title('Response as a Function of Stimulus Phase', fontsize=14)\n",
    "    ax6.set_xlabel('Stimulus Phase (degrees)')\n",
    "    ax6.set_ylabel('Normalized Response')\n",
    "    ax6.set_xticks(np.arange(0, 360, 45))\n",
    "    ax6.set_xlim(0, 360)\n",
    "    ax6.legend(loc='lower center')\n",
    "    ax6.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "illustrate_quadrature_pairs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Direction-Selective V1 Cells → Motion Energy Computation\n",
    "\n",
    "Direction-selective V1 cells with space-time inseparable receptive fields map to the directional motion energy computation in models. This includes:\n",
    "\n",
    "- Spatiotemporal filters with space-time inseparability\n",
    "- Directional tuning through specific filter orientations in space-time\n",
    "- Responses that vary with stimulus motion direction\n",
    "\n",
    "In computational models, directional selectivity is achieved by creating spatiotemporal filters oriented in space-time, effectively implementing velocity tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def illustrate_direction_selectivity():\n",
    "    \"\"\"Illustrate the relationship between direction-selective cells and motion energy computation\"\"\"\n",
    "    # Create space and time dimensions\n",
    "    x = np.linspace(-10, 10, 100)\n",
    "    t = np.linspace(0, 10, 50)\n",
    "    X, T = np.meshgrid(x, t)\n",
    "    \n",
    "    # Create space-time inseparable filters (right and left direction tuned)\n",
    "    def stfilter(X, T, velocity, sigma_x=2.0, sigma_t=1.0, spatial_freq=0.3):\n",
    "        # Create tilted coordinates for space-time inseparability\n",
    "        X_tilted = X - velocity * T\n",
    "        \n",
    "        # Spatial gabor\n",
    "        spatial = np.exp(-X_tilted**2 / (2*sigma_x**2)) * np.cos(2*np.pi*spatial_freq*X_tilted)\n",
    "        \n",
    "        # Temporal envelope\n",
    "        temporal = np.exp(-T**2 / (2*sigma_t**2))\n",
    "        \n",
    "        return spatial * temporal\n",
    "    \n",
    "    # Create the filters\n",
    "    rightward_filter = stfilter(X, T, velocity=1.0)  # Prefers rightward motion\n",
    "    leftward_filter = stfilter(X, T, velocity=-1.0)  # Prefers leftward motion\n",
    "    \n",
    "    # Create moving edge stimuli\n",
    "    def moving_edge(X, T, velocity):\n",
    "        return (X > velocity * T).astype(float)\n",
    "    \n",
    "    rightward_edge = moving_edge(X, T, velocity=1.0)\n",
    "    leftward_edge = moving_edge(X, T, velocity=-1.0)\n",
    "    \n",
    "    # Compute filter responses\n",
    "    right_filter_right_stim = np.sum(rightward_filter * rightward_edge)\n",
    "    right_filter_left_stim = np.sum(rightward_filter * leftward_edge)\n",
    "    left_filter_right_stim = np.sum(leftward_filter * rightward_edge)\n",
    "    left_filter_left_stim = np.sum(leftward_filter * leftward_edge)\n",
    "    \n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    gs = fig.add_gridspec(3, 4)\n",
    "    \n",
    "    # Top row: Space-time filters\n",
    "    ax1 = fig.add_subplot(gs[0, 0:2])\n",
    "    im1 = ax1.imshow(rightward_filter, cmap='RdBu_r', aspect='auto',\n",
    "                    extent=[x.min(), x.max(), t.max(), t.min()])\n",
    "    ax1.set_title('Rightward Direction-Selective Filter', fontsize=12)\n",
    "    ax1.set_xlabel('Space (x)')\n",
    "    ax1.set_ylabel('Time (t)')\n",
    "    plt.colorbar(im1, ax=ax1, shrink=0.8)\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[0, 2:4])\n",
    "    im2 = ax2.imshow(leftward_filter, cmap='RdBu_r', aspect='auto',\n",
    "                    extent=[x.min(), x.max(), t.max(), t.min()])\n",
    "    ax2.set_title('Leftward Direction-Selective Filter', fontsize=12)\n",
    "    ax2.set_xlabel('Space (x)')\n",
    "    ax2.set_ylabel('Time (t)')\n",
    "    plt.colorbar(im2, ax=ax2, shrink=0.8)\n",
    "    \n",
    "    # Middle row: Stimulus space-time plots\n",
    "    ax3 = fig.add_subplot(gs[1, 0:2])\n",
    "    ax3.imshow(rightward_edge, cmap='gray', aspect='auto',\n",
    "              extent=[x.min(), x.max(), t.max(), t.min()])\n",
    "    ax3.set_title('Rightward Moving Edge', fontsize=12)\n",
    "    ax3.set_xlabel('Space (x)')\n",
    "    ax3.set_ylabel('Time (t)')\n",
    "    \n",
    "    ax4 = fig.add_subplot(gs[1, 2:4])\n",
    "    ax4.imshow(leftward_edge, cmap='gray', aspect='auto',\n",
    "              extent=[x.min(), x.max(), t.max(), t.min()])\n",
    "    ax4.set_title('Leftward Moving Edge', fontsize=12)\n",
    "    ax4.set_xlabel('Space (x)')\n",
    "    ax4.set_ylabel('Time (t)')\n",
    "    \n",
    "    # Bottom row: Response bar chart\n",
    "    ax5 = fig.add_subplot(gs[2, 1:3])\n",
    "    \n",
    "    # Normalize responses for better visualization\n",
    "    max_response = max(abs(right_filter_right_stim), abs(right_filter_left_stim),\n",
    "                       abs(left_filter_right_stim), abs(left_filter_left_stim))\n",
    "    responses = [right_filter_right_stim/max_response, right_filter_left_stim/max_response,\n",
    "                left_filter_right_stim/max_response, left_filter_left_stim/max_response]\n",
    "    \n",
    "    labels = ['Right Filter\\nRight Stimulus', 'Right Filter\\nLeft Stimulus',\n",
    "             'Left Filter\\nRight Stimulus', 'Left Filter\\nLeft Stimulus']\n",
    "    colors = ['lightblue', 'salmon', 'salmon', 'lightblue']\n",
    "    \n",
    "    bars = ax5.bar(range(len(responses)), responses, color=colors)\n",
    "    ax5.set_xticks(range(len(responses)))\n",
    "    ax5.set_xticklabels(labels)\n",
    "    ax5.set_ylabel('Normalized Response')\n",
    "    ax5.set_title('Direction-Selective Filter Responses', fontsize=14)\n",
    "    ax5.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Add biological vs. computational labels\n",
    "    fig.text(0.05, 0.95, 'Biological Direction-Selective V1 Neurons', fontsize=14, fontweight='bold')\n",
    "    fig.text(0.05, 0.75, 'Motion Energy Model Spatiotemporal Filters', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "illustrate_direction_selectivity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. MT Pattern Cells → Filter Banks & Integration\n",
    "\n",
    "MT pattern cells, which integrate V1 outputs to solve problems like the aperture problem, map to the higher-level integration stage in motion energy models. This corresponds to:\n",
    "\n",
    "- Integration across multiple V1-like filters\n",
    "- Creation of filter banks tuned to different directions/speeds\n",
    "- Resolution of ambiguities through integration\n",
    "- Global motion computations from local measurements\n",
    "\n",
    "In computational models, this integration stage allows for more robust motion detection and velocity estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def illustrate_mt_integration():\n",
    "    \"\"\"Illustrate the integration of V1 outputs by MT and filter banks in models\"\"\"\n",
    "    # Create a figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    ax.set_xlim(0, 10)\n",
    "    ax.set_ylim(0, 10)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Create V1 filters with different orientations\n",
    "    v1_positions = [(2, y) for y in [8, 6.5, 5, 3.5, 2]]\n",
    "    v1_orientations = [0, 45, 90, 135, 180]\n",
    "    \n",
    "    for (x, y), orientation in zip(v1_positions, v1_orientations):\n",
    "        # Create an oriented bar to represent the V1 filter\n",
    "        angle_rad = np.deg2rad(orientation)\n",
    "        dx = 0.7 * np.cos(angle_rad)\n",
    "        dy = 0.7 * np.sin(angle_rad)\n",
    "        \n",
    "        # Draw the oriented filter\n",
    "        ax.plot([x-dx, x+dx], [y-dy, y+dy], 'b-', linewidth=3)\n",
    "        \n",
    "        # Draw the filter circle\n",
    "        circle = plt.Circle((x, y), 0.8, fc='lightblue', ec='blue', alpha=0.7)\n",
    "        ax.add_patch(circle)\n",
    "        \n",
    "        # Add label\n",
    "        ax.text(x, y, f\"V1\\n{orientation}°\", ha='center', va='center', fontsize=9)\n",
    "    \n",
    "    # Create MT integration cell\n",
    "    mt_pos = (5, 5)\n",
    "    mt_circle = plt.Circle(mt_pos, 1.2, fc='lightgreen', ec='green', alpha=0.7)\n",
    "    ax.add_patch(mt_circle)\n",
    "    ax.text(mt_pos[0], mt_pos[1], \"MT\\nPattern\\nCell\", ha='center', va='center', fontsize=10)\n",
    "    \n",
    "    # Create arrows from V1 to MT\n",
    "    for v1_pos in v1_positions:\n",
    "        ax.annotate(\"\", xy=mt_pos, xytext=v1_pos,\n",
    "                   arrowprops=dict(arrowstyle=\"->\", lw=1.5, color='gray'))\n",
    "    \n",
    "    # Create motion energy model components on the right\n",
    "    model_positions = [(8, y) for y in [8, 6.5, 5, 3.5, 2]]\n",
    "    model_labels = [\n",
    "        \"0° Filter\\nBank\",\n",
    "        \"45° Filter\\nBank\",\n",
    "        \"90° Filter\\nBank\",\n",
    "        \"135° Filter\\nBank\",\n",
    "        \"180° Filter\\nBank\"\n",
    "    ]\n",
    "    \n",
    "    for (x, y), label in zip(model_positions, model_labels):\n",
    "        # Draw the model component\n",
    "        rect = plt.Rectangle((x-0.8, y-0.5), 1.6, 1, fc='lightgreen', ec='green', alpha=0.7)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x, y, label, ha='center', va='center', fontsize=9)\n",
    "    \n",
    "    # Create integration component\n",
    "    integrator_pos = (8, 5)\n",
    "    \n",
    "    # Add arrows from filter banks to integration point\n",
    "    for model_pos in model_positions:\n",
    "        # Create dashed lines to show logical flow\n",
    "        ax.plot([model_pos[0], 9.5], [model_pos[1], model_pos[1]], 'g--', alpha=0.7)\n",
    "    \n",
    "    # Draw the final velocity output\n",
    "    ax.add_patch(plt.Rectangle((9, 3.5), 1, 3, fc='gold', ec='orange', alpha=0.7))\n",
    "    ax.text(9.5, 5, \"Motion\\nEnergy\\nMap\", ha='center', va='center', fontsize=10)\n",
    "    \n",
    "    # Add parallel processing arrows\n",
    "    ax.annotate(\"\", xy=(9, 5), xytext=(9.5, 8),\n",
    "               arrowprops=dict(arrowstyle=\"->\", lw=1.5, color='green', linestyle='--'))\n",
    "    ax.annotate(\"\", xy=(9, 5), xytext=(9.5, 2),\n",
    "               arrowprops=dict(arrowstyle=\"->\", lw=1.5, color='green', linestyle='--'))\n",
    "    \n",
    "    # Add titles\n",
    "    ax.text(2, 9, \"Biological Visual System\", ha='center', va='center', \n",
    "           fontsize=14, fontweight='bold', color='blue')\n",
    "    ax.text(8, 9, \"Motion Energy Model\", ha='center', va='center', \n",
    "           fontsize=14, fontweight='bold', color='green')\n",
    "    \n",
    "    # Add arrows to show flow from V1 to MT\n",
    "    ax.annotate(\"\", xy=(2, 1), xytext=(2, 9),\n",
    "               arrowprops=dict(arrowstyle=\"<->\", lw=2, color='blue'))\n",
    "    ax.text(1.3, 5, \"V1 → MT\\nHierarchical\\nProcessing\", rotation=90, va='center', \n",
    "           fontsize=10, color='blue')\n",
    "    \n",
    "    # Add arrows for model processing\n",
    "    ax.annotate(\"\", xy=(8, 1), xytext=(8, 9),\n",
    "               arrowprops=dict(arrowstyle=\"<->\", lw=2, color='green'))\n",
    "    ax.text(7.3, 5, \"Parallel\\nProcessing\\nand\\nIntegration\", rotation=90, va='center', \n",
    "           fontsize=10, color='green')\n",
    "    \n",
    "    plt.title(\"Integration in MT and Filter Banks in Motion Energy Models\", fontsize=16, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "illustrate_mt_integration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Motion Energy Relates to Neural Computations\n",
    "\n",
    "The motion energy model provides a computational framework that closely aligns with neural processes in the visual system. This relationship is evident in several key aspects:\n",
    "\n",
    "### 1. Physiological Validation\n",
    "\n",
    "The motion energy model has been extensively validated against physiological data:\n",
    "\n",
    "- **Response predictions**: The model accurately predicts how direction-selective neurons respond to various motion stimuli\n",
    "- **Tuning curves**: Directional and speed tuning curves of model filters match those of actual neurons\n",
    "- **Illusions**: The model experiences the same motion illusions that affect human perception\n",
    "\n",
    "### 2. Neural Plausibility\n",
    "\n",
    "The operations in the motion energy model are neurally plausible:\n",
    "\n",
    "- **Linear filtering**: Corresponds to the weighted summation performed by dendritic trees\n",
    "- **Squaring nonlinearity**: Aligns with nonlinear operations in neural processing (e.g., spike threshold, synaptic transmission)\n",
    "- **Spatial summation**: Matches the integration of inputs from multiple neurons\n",
    "\n",
    "### 3. Hierarchical Processing\n",
    "\n",
    "Both the visual system and the motion energy model use hierarchical processing:\n",
    "\n",
    "- **Low-level features**: Initial stages extract basic features like edges and temporal changes\n",
    "- **Mid-level integration**: Intermediate stages combine these features to detect motion direction\n",
    "- **High-level representation**: Later stages integrate multiple signals to represent global motion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biological Constraints on Motion Energy Models\n",
    "\n",
    "When implementing motion energy models, we should consider several biological constraints that shape how these models reflect actual neural processing:\n",
    "\n",
    "### 1. Receptive Field Properties\n",
    "\n",
    "- **Size and scale**: V1 receptive fields vary in size and scale, with larger RFs in the periphery\n",
    "- **Frequency tuning**: Neurons exhibit specific spatial and temporal frequency tuning\n",
    "- **Bandwidth**: Orientation and direction tuning have specific bandwidths (typically 30-60°)\n",
    "\n",
    "### 2. Temporal Dynamics\n",
    "\n",
    "- **Adaptation**: Neurons adapt to continuous stimulation\n",
    "- **Latency**: Neural responses have specific temporal delays\n",
    "- **Transient vs. sustained**: Different neurons show preference for transient or sustained stimuli\n",
    "\n",
    "### 3. Nonlinearities\n",
    "\n",
    "- **Saturation**: Neural responses saturate at high contrast\n",
    "- **Thresholding**: Neurons have activation thresholds\n",
    "- **Normalization**: Responses are normalized by divisive inhibition\n",
    "\n",
    "### 4. Integration Principles\n",
    "\n",
    "- **Weighted combination**: Different inputs are combined with specific weights\n",
    "- **Competition**: Competing motions can inhibit each other\n",
    "- **Global coherence**: Integration favors coherent motion interpretations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking Ahead: The Adelson & Bergen Motion Energy Model\n",
    "\n",
    "In the next module, we'll implement the Adelson & Bergen motion energy model, a foundational framework that incorporates many of the biological principles we've discussed. The model includes:\n",
    "\n",
    "1. **Spatiotemporal filtering**: Using space-time oriented Gabor filters\n",
    "2. **Quadrature pairs**: Combining filters with 90° phase differences\n",
    "3. **Energy computation**: Squaring and summing filter responses\n",
    "4. **Direction opponency**: Comparing motion energy in opposite directions\n",
    "5. **Filter banks**: Using multiple filters tuned to different directions and speeds\n",
    "\n",
    "This model provides a computational implementation that bridges the gap between neural mechanisms and algorithmic descriptions of motion processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've explored the critical connections between biological visual systems and computational motion energy models:\n",
    "\n",
    "1. We mapped key components of the visual pathway to their computational counterparts:\n",
    "   - Retinal ganglion cells → Spatial filtering\n",
    "   - LGN magnocellular cells → Temporal filtering\n",
    "   - V1 simple cells → Oriented spatiotemporal filters\n",
    "   - V1 complex cells → Quadrature pairs and energy computation\n",
    "   - Direction-selective V1 cells → Motion energy computation\n",
    "   - MT pattern cells → Filter banks and integration\n",
    "\n",
    "2. We examined how motion energy relates to neural computations, highlighting:\n",
    "   - Physiological validation\n",
    "   - Neural plausibility\n",
    "   - Hierarchical processing\n",
    "\n",
    "3. We discussed important biological constraints that should inform model implementation:\n",
    "   - Receptive field properties\n",
    "   - Temporal dynamics\n",
    "   - Nonlinearities\n",
    "   - Integration principles\n",
    "\n",
    "These connections provide a foundation for the next module, where we'll implement a complete motion energy model that captures key aspects of biological visual processing. By understanding the relationship between neural mechanisms and computational models, we can build more effective and biologically plausible systems for motion perception."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}