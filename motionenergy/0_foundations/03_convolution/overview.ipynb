 {
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d64bf4",
   "metadata": {},
   "source": [
    "# Convolution: A Fundamental Operation for Motion Energy Models\n",
    "\n",
    "## Overview\n",
    "\n",
    "Convolution is a mathematical operation that is central to understanding how motion energy models work. In this section, we'll explore convolution in detail, focusing on its application to visual processing and motion detection.\n",
    "\n",
    "### What we'll cover:\n",
    "- The mathematical definition of convolution\n",
    "- The intuition behind convolution in signal processing\n",
    "- 1D and 2D convolution operations\n",
    "- Implementing convolution from scratch\n",
    "- Convolution with various kernels and filters\n",
    "- The relationship between convolution and visual processing in the brain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccfad07",
   "metadata": {},
   "source": [
    "## Setting Up\n",
    "\n",
    "Let's import the libraries we'll need for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e86e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "import sys\n",
    "from matplotlib import animation\n",
    "\n",
    "# Add the utils package to the path\n",
    "sys.path.append('../../..')\n",
    "try:\n",
    "    from motionenergy.utils import stimuli_generation, visualization\n",
    "except ImportError:\n",
    "    print(\"Note: utils modules not found. This is expected if you haven't implemented them yet.\")\n",
    "\n",
    "# For interactive plots\n",
    "%matplotlib inline\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be953cf3",
   "metadata": {},
   "source": [
    "## 1. Introduction to Convolution\n",
    "\n",
    "Convolution is a mathematical operation that combines two functions to produce a third function that represents how the shape of one is modified by the other. In signal processing, convolution is often used to describe how an input signal is affected by a system or filter.\n",
    "\n",
    "### The Convolution Equation\n",
    "\n",
    "For continuous functions, the convolution of functions $f$ and $g$ is defined as:\n",
    "\n",
    "$(f * g)(t) = \\int_{-\\infty}^{\\infty} f(\\tau) g(t - \\tau) d\\tau$\n",
    "\n",
    "For discrete functions (like our digital images and signals), the convolution becomes a sum:\n",
    "\n",
    "$(f * g)[n] = \\sum_{m=-\\infty}^{\\infty} f[m] g[n - m]$\n",
    "\n",
    "While these equations may look intimidating, the intuition behind convolution is actually quite simple. Let's visualize it to build our understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e21fb4",
   "metadata": {},
   "source": [
    "## 2. Intuitive Understanding of Convolution\n",
    "\n",
    "Convolution can be intuitively understood as a process where one function is \"flipped\" and slid over another function, with the resulting function being the sum of the pointwise products at each position.\n",
    "\n",
    "Let's visualize this process for a simple 1D example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e9e2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_1d_convolution(signal_func, kernel_func, signal_range, kernel_range, num_positions=5):\n",
    "    \"\"\"\n",
    "    Visualize the convolution process for 1D signals.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signal_func : function\n",
    "        Function that generates the signal array\n",
    "    kernel_func : function\n",
    "        Function that generates the kernel array\n",
    "    signal_range : tuple\n",
    "        (start, end) of the signal domain\n",
    "    kernel_range : tuple\n",
    "        (start, end) of the kernel domain\n",
    "    num_positions : int\n",
    "        Number of kernel positions to visualize\n",
    "    \"\"\"\n",
    "    # Generate the signal and kernel\n",
    "    t_signal = np.linspace(signal_range[0], signal_range[1], 1000)\n",
    "    signal = signal_func(t_signal)\n",
    "    \n",
    "    t_kernel = np.linspace(kernel_range[0], kernel_range[1], 100)\n",
    "    kernel = kernel_func(t_kernel)\n",
    "    \n",
    "    # Normalize the kernel for visualization\n",
    "    kernel = kernel / np.max(np.abs(kernel))\n",
    "    \n",
    "    # Compute the full convolution\n",
    "    # We'll use scipy's convolve function with 'full' mode\n",
    "    # In 'full' mode, the output is the full discrete linear convolution\n",
    "    conv_result = signal.convolve(signal, kernel, mode='full')\n",
    "    \n",
    "    # Create a time axis for the convolution result\n",
    "    dt_signal = t_signal[1] - t_signal[0]\n",
    "    dt_kernel = t_kernel[1] - t_kernel[0]\n",
    "    t_conv = np.linspace(\n",
    "        t_signal[0] + t_kernel[0], \n",
    "        t_signal[-1] + t_kernel[-1], \n",
    "        len(conv_result)\n",
    "    )\n",
    "    \n",
    "    # Select positions for visualization\n",
    "    positions = np.linspace(0, len(t_signal) - 1, num_positions, dtype=int)\n",
    "    \n",
    "    # Create the figure\n",
    "    fig, axes = plt.subplots(num_positions + 1, 1, figsize=(10, 2 + 2 * num_positions))\n",
    "    \n",
    "    # Plot the signal and kernel at different positions\n",
    "    for i, pos in enumerate(positions):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Plot the signal\n",
    "        ax.plot(t_signal, signal, 'b-', label='Signal')\n",
    "        \n",
    "        # Position for the kernel\n",
    "        t_pos = t_signal[pos]\n",
    "        \n",
    "        # Plot the flipped and shifted kernel\n",
    "        # In convolution, the kernel is flipped and shifted\n",
    "        t_kernel_shifted = t_pos + np.flip(-t_kernel + t_kernel[0] + t_kernel[-1])\n",
    "        kernel_shifted = np.flip(kernel)\n",
    "        ax.plot(t_kernel_shifted, kernel_shifted, 'r-', label='Kernel')\n",
    "        \n",
    "        # Fill the area representing the product\n",
    "        # We need to interpolate the signal values at the kernel positions\n",
    "        y_interp = np.interp(t_kernel_shifted, t_signal, signal)\n",
    "        product = y_interp * kernel_shifted\n",
    "        ax.fill_between(t_kernel_shifted, 0, product, alpha=0.3, color='purple')\n",
    "        \n",
    "        # Mark the convolution result for this position\n",
    "        conv_pos = pos + len(t_kernel) - 1\n",
    "        if conv_pos < len(t_conv):\n",
    "            ax.plot([t_pos], [conv_result[conv_pos]], 'ko', markersize=5)\n",
    "            ax.text(t_pos, conv_result[conv_pos], f'  ({t_pos:.1f}, {conv_result[conv_pos]:.2f})')\n",
    "        \n",
    "        ax.set_title(f'Kernel Position {i+1}')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "    \n",
    "    # Plot the full convolution result\n",
    "    ax = axes[-1]\n",
    "    ax.plot(t_conv, conv_result, 'g-', label='Convolution Result')\n",
    "    \n",
    "    # Mark the positions we visualized above\n",
    "    for i, pos in enumerate(positions):\n",
    "        t_pos = t_signal[pos]\n",
    "        conv_pos = pos + len(t_kernel) - 1\n",
    "        if conv_pos < len(t_conv):\n",
    "            ax.plot([t_pos], [conv_result[conv_pos]], 'ko', markersize=5)\n",
    "    \n",
    "    ax.set_title('Full Convolution Result')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d61c4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Square wave signal and rectangular kernel\n",
    "def square_wave(t):\n",
    "    return (t > -2) & (t < 2)\n",
    "\n",
    "def rectangular_kernel(t):\n",
    "    return (t > -0.5) & (t < 0.5)\n",
    "\n",
    "# Visualize the convolution\n",
    "fig = visualize_1d_convolution(\n",
    "    square_wave, rectangular_kernel, \n",
    "    signal_range=(-5, 5), kernel_range=(-1, 1), \n",
    "    num_positions=5\n",
    ")\n",
    "plt.suptitle('Convolution of Square Wave with Rectangular Kernel', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])  # Make space for the suptitle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abcf6e3",
   "metadata": {},
   "source": [
    "Let's try another example with a Gaussian kernel, which is commonly used in signal processing and vision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af86452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Square wave signal and Gaussian kernel\n",
    "def gaussian_kernel(t, sigma=0.5):\n",
    "    return np.exp(-t**2 / (2 * sigma**2))\n",
    "\n",
    "# Visualize the convolution\n",
    "fig = visualize_1d_convolution(\n",
    "    square_wave, gaussian_kernel, \n",
    "    signal_range=(-5, 5), kernel_range=(-2, 2), \n",
    "    num_positions=5\n",
    ")\n",
    "plt.suptitle('Convolution of Square Wave with Gaussian Kernel', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])  # Make space for the suptitle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f26cb7",
   "metadata": {},
   "source": [
    "## 3. Implementing 1D Convolution from Scratch\n",
    "\n",
    "To deepen our understanding, let's implement the convolution operation from scratch for 1D signals. This will help us see exactly what's happening at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8cf9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_1d(signal, kernel):\n",
    "    \"\"\"\n",
    "    Implement 1D convolution from scratch.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signal : ndarray\n",
    "        Input signal\n",
    "    kernel : ndarray\n",
    "        Convolution kernel\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    output : ndarray\n",
    "        Convolved signal (using 'full' mode)\n",
    "    \"\"\"\n",
    "    # Flip the kernel for convolution\n",
    "    kernel_flipped = np.flip(kernel)\n",
    "    \n",
    "    # Output size for 'full' convolution\n",
    "    output_size = len(signal) + len(kernel) - 1\n",
    "    output = np.zeros(output_size)\n",
    "    \n",
    "    # Perform the convolution\n",
    "    for i in range(output_size):\n",
    "        # Determine the overlap between the signal and kernel at position i\n",
    "        kernel_start = max(0, i - len(signal) + 1)\n",
    "        kernel_end = min(len(kernel), i + 1)\n",
    "        signal_start = max(0, i - len(kernel) + 1)\n",
    "        signal_end = min(len(signal), i + 1)\n",
    "        \n",
    "        # Extract the overlapping parts\n",
    "        k = kernel_flipped[kernel_start:kernel_end]\n",
    "        s = signal[signal_start:signal_end]\n",
    "        \n",
    "        # Compute the sum of the pointwise product\n",
    "        output[i] = np.sum(k * s)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33c4324",
   "metadata": {},
   "source": [
    "Let's compare our implementation with the built-in convolution function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ed94cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple signal and kernel\n",
    "signal = np.array([1, 2, 3, 4, 5])\n",
    "kernel = np.array([0.5, 0.5, 0.5])\n",
    "\n",
    "# Compute the convolution using our function\n",
    "our_result = convolve_1d(signal, kernel)\n",
    "\n",
    "# Compute the convolution using scipy's function\n",
    "scipy_result = signal.convolve(signal, kernel, mode='full')\n",
    "\n",
    "# Compare the results\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 8))\n",
    "\n",
    "# Plot the signal and kernel\n",
    "axes[0].stem(range(len(signal)), signal, 'b', markerfmt='bo', basefmt=' ')\n",
    "axes[0].set_title('Signal')\n",
    "\n",
    "axes[1].stem(range(len(kernel)), kernel, 'r', markerfmt='ro', basefmt=' ')\n",
    "axes[1].set_title('Kernel')\n",
    "\n",
    "# Plot the results\n",
    "x = range(len(our_result))\n",
    "axes[2].stem(x, our_result, 'g', markerfmt='go', basefmt=' ', label='Our Convolution')\n",
    "axes[2].plot(x, scipy_result, 'k--', label='SciPy Convolution')\n",
    "axes[2].set_title('Convolution Results')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd2c6c5",
   "metadata": {},
   "source": [
    "## 4. 2D Convolution and Its Applications in Image Processing\n",
    "\n",
    "Now let's extend our understanding to 2D convolution, which is essential for image processing and will be critical for our motion energy models.\n",
    "\n",
    "In 2D convolution, we slide a 2D kernel over a 2D image, computing the sum of the element-wise products at each position. The mathematical formula is similar to the 1D case, but with double summations for rows and columns:\n",
    "\n",
    "$(I * K)[i, j] = \\sum_{m} \\sum_{n} I[i-m, j-n] K[m, n]$\n",
    "\n",
    "Where $I$ is the image and $K$ is the kernel.\n",
    "\n",
    "Let's implement 2D convolution and explore some common image processing kernels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf2ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_2d(image, kernel):\n",
    "    \"\"\"\n",
    "    Implement 2D convolution from scratch.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : ndarray\n",
    "        Input image (2D array)\n",
    "    kernel : ndarray\n",
    "        Convolution kernel (2D array)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    output : ndarray\n",
    "        Convolved image (using 'full' mode)\n",
    "    \"\"\"\n",
    "    # Get dimensions\n",
    "    image_rows, image_cols = image.shape\n",
    "    kernel_rows, kernel_cols = kernel.shape\n",
    "    \n",
    "    # Flip the kernel for convolution\n",
    "    kernel_flipped = np.flip(np.flip(kernel, 0), 1)\n",
    "    \n",
    "    # Output dimensions for 'full' convolution\n",
    "    output_rows = image_rows + kernel_rows - 1\n",
    "    output_cols = image_cols + kernel_cols - 1\n",
    "    output = np.zeros((output_rows, output_cols))\n",
    "    \n",
    "    # Perform the convolution\n",
    "    for i in range(output_rows):\n",
    "        for j in range(output_cols):\n",
    "            # Determine the overlap between the image and kernel at position (i, j)\n",
    "            kernel_row_start = max(0, i - image_rows + 1)\n",
    "            kernel_row_end = min(kernel_rows, i + 1)\n",
    "            kernel_col_start = max(0, j - image_cols + 1)\n",
    "            kernel_col_end = min(kernel_cols, j + 1)\n",
    "            \n",
    "            img_row_start = max(0, i - kernel_rows + 1)\n",
    "            img_row_end = min(image_rows, i + 1)\n",
    "            img_col_start = max(0, j - kernel_cols + 1)\n",
    "            img_col_end = min(image_cols, j + 1)\n",
    "            \n",
    "            # Extract the overlapping parts\n",
    "            k = kernel_flipped[kernel_row_start:kernel_row_end, kernel_col_start:kernel_col_end]\n",
    "            img = image[img_row_start:img_row_end, img_col_start:img_col_end]\n",
    "            \n",
    "            # Compute the sum of the pointwise product\n",
    "            output[i, j] = np.sum(k * img)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9deefe9",
   "metadata": {},
   "source": [
    "Let's create some common image processing kernels and see them in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b94334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some common kernels\n",
    "kernels = {\n",
    "    'Box blur': np.ones((3, 3)) / 9,\n",
    "    'Gaussian blur': np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]]) / 16,\n",
    "    'Sharpen': np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]),\n",
    "    'Edge detection': np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]]),\n",
    "    'Sobel X': np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]),\n",
    "    'Sobel Y': np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "}\n",
    "\n",
    "# Visualize the kernels\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (name, kernel) in enumerate(kernels.items()):\n",
    "    im = axes[i].imshow(kernel, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[i].set_title(name)\n",
    "    axes[i].set_xticks([])\n",
    "    axes[i].set_yticks([])\n",
    "    plt.colorbar(im, ax=axes[i])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a7ff22",
   "metadata": {},
   "source": [
    "Let's create a simple test image and apply these kernels to see their effects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15e19b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple test image\n",
    "def create_test_image(size=64):\n",
    "    # Create an empty image\n",
    "    image = np.zeros((size, size))\n",
    "    \n",
    "    # Add a square\n",
    "    image[size//4:3*size//4, size//4:3*size//4] = 0.5\n",
    "    \n",
    "    # Add a smaller square with higher intensity\n",
    "    image[3*size//8:5*size//8, 3*size//8:5*size//8] = 1.0\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Create the test image\n",
    "test_image = create_test_image(64)\n",
    "\n",
    "# Apply the kernels and display the results\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Display the original image\n",
    "axes[0].imshow(test_image, cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].set_xticks([])\n",
    "axes[0].set_yticks([])\n",
    "\n",
    "# Apply each kernel and display the result\n",
    "for i, (name, kernel) in enumerate(kernels.items(), 1):\n",
    "    # Apply the kernel using SciPy's convolve2d function\n",
    "    # We use 'same' mode to get an output of the same size as the input\n",
    "    filtered = signal.convolve2d(test_image, kernel, mode='same', boundary='symm')\n",
    "    \n",
    "    # Display the filtered image\n",
    "    im = axes[i].imshow(filtered, cmap='gray')\n",
    "    axes[i].set_title(name)\n",
    "    axes[i].set_xticks([])\n",
    "    axes[i].set_yticks([])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f11f81",
   "metadata": {},
   "source": [
    "## 5. Separable Convolution: A Computational Advantage\n",
    "\n",
    "In some cases, a 2D convolution kernel can be expressed as the outer product of two 1D kernels. Such kernels are called \"separable\" and provide significant computational advantages, as the 2D convolution can be performed as two sequential 1D convolutions.\n",
    "\n",
    "For example, a 2D Gaussian kernel is separable into the outer product of two 1D Gaussian kernels:\n",
    "\n",
    "$G(x, y) = G_x(x) \\cdot G_y(y)$\n",
    "\n",
    "Let's demonstrate this with a Gaussian filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11c68c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1D Gaussian kernels\n",
    "def gaussian_1d(size, sigma=1.0):\n",
    "    x = np.linspace(-size//2, size//2, size)\n",
    "    return np.exp(-x**2 / (2 * sigma**2))\n",
    "\n",
    "# Create a separable 2D Gaussian\n",
    "size = 9\n",
    "sigma = 1.5\n",
    "\n",
    "g_x = gaussian_1d(size, sigma)\n",
    "g_y = gaussian_1d(size, sigma)\n",
    "\n",
    "# Create the 2D Gaussian as the outer product\n",
    "g_2d_separable = np.outer(g_y, g_x)\n",
    "\n",
    "# Normalize\n",
    "g_2d_separable /= np.sum(g_2d_separable)\n",
    "\n",
    "# Create a non-separable 2D Gaussian (but it should be very similar)\n",
    "x, y = np.meshgrid(np.linspace(-size//2, size//2, size), np.linspace(-size//2, size//2, size))\n",
    "g_2d_direct = np.exp(-(x**2 + y**2) / (2 * sigma**2))\n",
    "g_2d_direct /= np.sum(g_2d_direct)\n",
    "\n",
    "# Compare the two methods\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# 1D kernels\n",
    "axes[0].plot(g_x, 'b-', label='G_x')\n",
    "axes[0].plot(g_y, 'r--', label='G_y')\n",
    "axes[0].set_title('1D Gaussian Kernels')\n",
    "axes[0].legend()\n",
    "\n",
    "# 2D separable Gaussian\n",
    "im1 = axes[1].imshow(g_2d_separable, cmap='viridis')\n",
    "axes[1].set_title('2D Gaussian (Separable)')\n",
    "plt.colorbar(im1, ax=axes[1])\n",
    "\n",
    "# 2D direct Gaussian\n",
    "im2 = axes[2].imshow(g_2d_direct, cmap='viridis')\n",
    "axes[2].set_title('2D Gaussian (Direct)')\n",
    "plt.colorbar(im2, ax=axes[2])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1dfde8",
   "metadata": {},
   "source": [
    "Let's compare the computational efficiency of separable vs. direct 2D convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7bd7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Create a larger test image for better timing\n",
    "large_image = create_test_image(256)\n",
    "\n",
    "# Function to apply separable convolution\n",
    "def apply_separable_convolution(image, kernel_x, kernel_y):\n",
    "    # Apply 1D convolution along rows\n",
    "    temp = np.zeros_like(image)\n",
    "    for i in range(image.shape[0]):\n",
    "        temp[i, :] = signal.convolve(image[i, :], kernel_x, mode='same')\n",
    "    \n",
    "    # Apply 1D convolution along columns\n",
    "    result = np.zeros_like(image)\n",
    "    for j in range(image.shape[1]):\n",
    "        result[:, j] = signal.convolve(temp[:, j], kernel_y, mode='same')\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Time the methods\n",
    "# Direct 2D convolution\n",
    "start_time = time.time()\n",
    "result_direct = signal.convolve2d(large_image, g_2d_direct, mode='same', boundary='symm')\n",
    "direct_time = time.time() - start_time\n",
    "\n",
    "# Separable 2D convolution\n",
    "start_time = time.time()\n",
    "result_separable = apply_separable_convolution(large_image, g_x, g_y)\n",
    "separable_time = time.time() - start_time\n",
    "\n",
    "print(f\"Direct 2D convolution time: {direct_time:.4f} seconds\")\n",
    "print(f\"Separable 2D convolution time: {separable_time:.4f} seconds\")\n",
    "print(f\"Speedup: {direct_time / separable_time:.2f}x\")\n",
    "\n",
    "# Compare the results\n",
    "error = np.max(np.abs(result_direct - result_separable))\n",
    "print(f\"Maximum absolute error: {error:.10f}\")\n",
    "\n",
    "# Visualize the results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(large_image, cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].set_xticks([])\n",
    "axes[0].set_yticks([])\n",
    "\n",
    "axes[1].imshow(result_direct, cmap='gray')\n",
    "axes[1].set_title(f'Direct 2D Convolution\\n({direct_time:.4f} s)')\n",
    "axes[1].set_xticks([])\n",
    "axes[1].set_yticks([])\n",
    "\n",
    "axes[2].imshow(result_separable, cmap='gray')\n",
    "axes[2].set_title(f'Separable 2D Convolution\\n({separable_time:.4f} s)')\n",
    "axes[2].set_xticks([])\n",
    "axes[2].set_yticks([])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffbf0d7",
   "metadata": {},
   "source": [
    "## 6. Convolution in the Frequency Domain\n",
    "\n",
    "One of the important properties of convolution is that it corresponds to multiplication in the frequency domain. The Fourier transform of the convolution of two functions is equal to the product of their Fourier transforms:\n",
    "\n",
    "$\\mathcal{F}\\{f * g\\} = \\mathcal{F}\\{f\\} \\cdot \\mathcal{F}\\{g\\}$\n",
    "\n",
    "This property is particularly useful for understanding how filtering works in the frequency domain and for implementing efficient convolution using the Fast Fourier Transform (FFT). We'll explore this more in the next section on Fourier transforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56781731",
   "metadata": {},
   "source": [
    "## 7. Convolution in Visual Processing\n",
    "\n",
    "In the context of visual neuroscience and motion energy models, convolution plays a crucial role in modeling how neurons process visual information.\n",
    "\n",
    "### Receptive Fields\n",
    "\n",
    "Neurons in the visual cortex have spatially localized receptive fields, which determine how they respond to visual stimuli. These receptive fields can be modeled as convolution kernels that are applied to the visual input. The output of the convolution represents the neuron's response to the visual stimulus.\n",
    "\n",
    "### Hierarchical Processing\n",
    "\n",
    "The visual system processes information hierarchically, with each level of processing building upon the previous one. Convolution provides a mathematical framework for understanding this hierarchical processing:\n",
    "\n",
    "1. At the retinal level, center-surround receptive fields can be modeled as difference-of-Gaussians kernels\n",
    "2. In the primary visual cortex (V1), simple cells have oriented receptive fields that can be modeled as Gabor filters\n",
    "3. Complex cells in V1 integrate the responses of multiple simple cells, which can be modeled as a nonlinear combination of the outputs of multiple convolutions\n",
    "\n",
    "### Motion Energy Models\n",
    "\n",
    "In motion energy models, convolution with spatiotemporal filters is used to extract motion information from the visual input. These filters are selective for specific directions and speeds of motion. We'll explore these spatiotemporal filters in more detail in later sections of the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7f5c9c",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "In this section, we've explored convolution, a fundamental operation in signal processing and computational neuroscience. Here's a summary of what we've learned:\n",
    "\n",
    "1. **Convolution basics**: Convolution combines two functions to produce a third function that represents how one function modifies the shape of the other.\n",
    "\n",
    "2. **1D and 2D convolution**: We implemented and visualized both 1D and 2D convolution operations, gaining an intuitive understanding of how they work.\n",
    "\n",
    "3. **Image processing applications**: We explored common image processing kernels like Gaussian blur, edge detection, and Sobel filters, which are all based on convolution.\n",
    "\n",
    "4. **Separable convolution**: We learned about separable kernels, which can significantly reduce the computational cost of 2D convolution.\n",
    "\n",
    "5. **Convolution in the frequency domain**: We briefly touched on the relationship between convolution and multiplication in the frequency domain, which we'll explore further in the next section.\n",
    "\n",
    "6. **Convolution in visual processing**: We discussed how convolution models the way neurons in the visual system process information, from retinal ganglion cells to complex cells in the visual cortex.\n",
    "\n",
    "In the next section, we'll dive into the Fourier transform, which will provide us with another powerful tool for understanding motion perception and motion energy models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c741ee1f",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "- Smith, S. W. (1997). The Scientist and Engineer's Guide to Digital Signal Processing. California Technical Publishing. Chapter 6: Convolution.\n",
    "- Marr, D. (1982). Vision: A Computational Investigation into the Human Representation and Processing of Visual Information. W. H. Freeman and Company.\n",
    "- Carandini, M., Demb, J. B., Mante, V., Tolhurst, D. J., Dan, Y., Olshausen, B. A., ... & Rust, N. C. (2005). Do we know what the early visual system does? Journal of Neuroscience, 25(46), 10577-10597."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
